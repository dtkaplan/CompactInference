[
["index.html", "A Compact Guide to Classical Inference Preface", " A Compact Guide to Classical Inference Daniel Kaplan 2020-03-26 Preface Statistical inference is the heart of many contemporary college-level statistics courses. By far the most common way of teaching inference features algebraic formulas for standard errors and test statistics. Probability tables are then used to scale standard errors into confidence intervals and translate test statistics into p-values. Generations of students have been taught using this “standard-error curriculum.” Its difficulties and pedagogical shortcomings are well known. Students in general have a hard time with algebra. Even for those select students who are confident reading and interpreting formulas, the tractable formulas for inference work only with simple statistics – means, proportions, slopes – in settings with at most two variables. When it comes time to deal with other statistical settings, new and seemingly unrelated methods are introduced. For instance, inference on tables of counts or on multiple means does not involve calculating a standard error, but uses other statistical procedures such as \\(\\chi^2\\) and ANOVA, each of which comes with a new table for the corresponding probability distributions. Both students and instructors perceive standard-error statistics as a confusing collection of specialized tools. To improve student learning, instructors long for a reduction in the number of topics needed to support statistical thinking. This book is a roadmap for instructors who wish to simplify inference while continuing to teach using traditional tools. Simplified does not mean simplistic. The strategy for teaching provided by this book produces answers that fully comply with legitimate uses of statistical inference. How? Conventionally, the logic of introductory inference recapitulates the historical route to the development of statistical concepts from 1880 to 1910. Instead of following every twist and turn in that path, this book uses modern modeling terminology – response and explanatory variables, functions, model output – and the concepts of analysis of variance developed around 1925. For the “non-traditional” instructor who embraces modern computing, there is an important and effective alternative approach to inference based on simulation, randomization, and statistical bootstrapping. (See, e.g., Lock et al. (2017), Diez, Barr, and Çetinkaya-Rundel (2014), Tintle et al. (2016), Ismay and Kim (2019).) But for many instructors, particularly those strongly oriented toward mathematics rather than computing, the formula-based line of attack seems more natural. With formulas, there is a unique correct answer, while with randomization there is a process generating answers that differ (somewhat) from one realization to another. The formulas build on the strong mathematics traditions of exactitude and using algebraic notation; they look like math. In many traditional, formula-based curricula, computers are not used: a calculator and a set of printed probability tables are sufficient to the task. This is only tenable because the task has been defined in a narrow way. It excludes modern data graphics. And it precludes any careful examination of confounding and the acknowledgement that many important questions can only be addressed by considering the relationships among multiple variables. I hope that this little book can help instructors see that statistical inference can be handled as one topic among the many needed for modern statistics. Inference, important though it be, does not need to be such a sprawling set of methods and details taking up so much of the introductory course that other essential topics get neglected. Daniel Kaplan, December 2019, Saint Paul, Minnesota References "],
["what-is-classical-inference.html", "Chapter 1 What is classical inference? … and why should I read this book?", " Chapter 1 What is classical inference? Statistical inference is the logic and methods for creating statistical claims that are justified by data. A statistical claim is a statement like this: My data show that taking aspirin is associated with a reduction in fever. Or this: My data show that for every year of age, middle-aged runners slow down, on average, by 20-40 seconds per mile. Statistical inference was invented to guard against spurious claims. For instance, suppose you had these data on age and running times (in minutes) in a 10-mile road race: Person Age Running Time John 48 105 Abigail 40 101 Just comparing the ages and running times of John and Abigail, you can see that John is 4 minutes (that is, 240 seconds) slower than Abigail in completing the 10 mile run. Their age difference is 8 years. This amounts to an additional 30 seconds of running time per year of age difference. (240 / 8 = 30.) Since you are uncertain—this is only one race, this is only two people, etc.—you decide to frame your findings this way: “My data show that middle-aged runners slow down by 20-40 seconds/mile for every year additional age.” That is a statistical claim. There are many problems with this statistical claim. First, it’s comparing people who differ in many ways, not just their 8-year spread in age. In this case, John is a man and Abigail a woman. A different statistical claim, equally consistent with the data, is that women are faster than men by 30 seconds per mile. Or, it might be that Abigail is an experienced runner and John is running his first race. Common sense – and good statistical practice – tells you to compare like with like. Wouldn’t it be better to compare men of different ages who are both running their first 10-mile race? This would hold constant both experience and sex. Or, how about comparing Abigail’s running time this year to her running times in previous years? Failing to design the study to compare like with like is reason enough to be skeptical about the 20-40 seconds/mile per year claim. But flaws in study design, however grevious, are not what statistical inference deals with. Statistical inference deals with one, and only one, source of uncertainty: that produced by the size of the sample, in this case 2 people. Again, common sense tells you that two is not a lot of data. So, how much would be enough? 10? 100? 1000? Or, put another way, how should you frame the uncertainty in your claim due to limited data? In the example, the 20-40 seconds/mile per year interval was made up to create an impression of scientific precision. Statistical inference techniques create meaningful intervals that stem from the data itself, rather than the imagination of the researcher. The need for statistical inference became important when it was realized, around 1900, that there was not yet a reliable way of knowing how much data—that is, how many rows of data—is sufficient. The founders of statistical inference found ways to frame the problem in terms of the mathematics of probability and employed algebra and other mathematical techniques to solve the problem. They summarized the process of statistical inference using formulas and tables of probabilities. This is classical inference. Algebra and other mathematical arguments can be difficult and subtle. In the early days of classical inference, there were disagreements about what formulas were appropriate. To develop ideas and confirm that their formulas gave reasonable results, some of the founders of classical inference used simulations. One simulation, for instance, involved writing down data for 3000 individual people on index cards, shuffling the cards, then dealing out hands of 4 cards each. With 1000 such events, it was straightforward—but extremely tedious—to see which results were likely and which not. The algebraic techniques were pretty much the only way to conduct statistical inference until the 1970s. Then, as computing became available at research institutions, the simulation technique became easy enough to be practical for routine problems in statistical inference. Simulation on computers became a potent substitute for algebra. The simulation approach to statistical inference has been called computer-age statistical inference to distinguish it from classical statistical inference. … and why should I read this book? We live in the computer age, so you might suppose that statistics courses would use computer-age statistical inference. But by and large they do not. There is one good reason and several bad reasons for this. And these reasons – good and bad – determine whether you should read this book. Classical inference is the only way to conduct statistical inference for very small data, say with 10 or fewer rows of data. So if you are working with small data, you need classical inference. Putting aside the matter of small data, instructors use classical inference because that is what they were taught. They don’t use simulation for a variety of reasons: they may not know about the computer-age techniques, they may not be comfortable teaching how to use a computer, they may see algebra as prestigious and computing as low-class, they may think their students don’t have access to computing (and in some places, this might be true), they may have been forced to use the nth edition of a textbook originally written before computer-age inference was accessible and which continues to use classical inference to retain established clients. If you going to study classical inference, you might as well study it concisely. Traditional statistics textbooks introduce many ways of summarizing data—means here, proportions there, slopes in another place, correlation coefficients still elsewhere. But these seemingly diverse elements are merely different perspectives on a common theme: fitting a statistical model to data. Putting statistical models at the center of inference streamlines and simplifies the logic. And, rather than laboring over unnecessarily detailed tables of probability, it’s better to focus on the essential ambiguities of inference: covariation, multiple testing, researcher degrees of freedom, publication bias, etc. "],
["data-and-variables.html", "Chapter 2 Data and variables 2.1 Data frames 2.2 Tabulations 2.3 Quantitative and categorical variables 2.4 Response and explanatory variables", " Chapter 2 Data and variables Only in the second half of the twentieth century was the organization of data treated as a serious topic. Classical inference, emerging mainly in the period 1880-1925, was developed without reference to standard formats for data. Without automated methods of data handling, each researcher was confronted with the “oppressive necessity of reducing his results to a more convenient bulk.”1 Although this book is a guide to classical inference, we will work with data in a contemporary, standard format. This simplifies inference since we do not need to develop different statistical methodologies to deal with the diverse ways in which raw data can be reduced to a “convenient bulk.” This chapter is about the organization of data. Later, we’ll work with a standard form for reducing data: statistical model functions. 2.1 Data frames The data we use is organized into data frames, which are more or less spreadsheets. The columns of the data frame are variables, the rows of the data frame are units of observation. As an example, consider data collected by Francis Galton, one of the pioneers of statistics. In the 1880s, seeking to understand genetic inheritance from parent to child, Galton visited almost 200 families in London with both parents living and children who had grown up. Galton recorded the height of the mother and father, and the height and sex of each of the adult children. Figure 2.1 shows part of the data frame. Figure 2.1: The Galton data frame containing Galton’s measurements of 898 adult children. family father mother sex height nkids 1 78.5 67.0 M 73.2 4 1 78.5 67.0 F 69.2 4 1 78.5 67.0 F 69.0 4 1 78.5 67.0 F 69.0 4 2 75.5 66.5 M 73.5 4 2 75.5 66.5 M 72.5 4 2 75.5 66.5 F 65.5 4 2 75.5 66.5 F 65.5 4 3 75.0 64.0 M 71.0 2 3 75.0 64.0 F 68.0 2 … and so on for 898 rows altogether. Each row corresponds to a unit of analysis, in this case, a person. The first row is a 6 foot 1.2 inch man in a family with 4 kids altogether. Looking at the next three rows, you see his three sisters, who are quite tall for the time (5 foot 9 inches) but not as tall as their parents. Their mother was a bit shorter (5 foot 7) and their father was very tall even by today’s standards: 6 feet 6.5 inches. The family is designated with a number. So all four of the first rows are kids in family one, while rows 5 and 6 come from family two. Most of the variables are numeric, as appropriate for height and the number of kids. One variable, sex, has values that are labels, M and F here, standing for male and female. Such variables are called categorical; the possible labels are the levels of the variable. In this book, categorical variables with two levels will play a very important role, but certainly there are categorical variables with more than two levels, as we shall see. 2.2 Tabulations Historically, when data was shared by printing it and when calculations were tedious, data would often be presented as tabulations. For instance, one of the very early (Bateson, Saunders, and Punnett (1905), p. 93) investigations of cross-linkage in genetics examined 799 sweet pea plants, recording the color of the flower and whether the pollen was round or elongated. Figure 2.2: Genetics data from 1905 This style of presentation is perfectly understandable, but it is not in the modern format for data. As a data frame, the observations underlying Figure 2.2 would look like Figure 2.3: Figure 2.3: Punnett’s data in a contemporary format ID flower_color pollen_shape SP790 other long SP50 other long SP4550 other long SP5830 other round SP2710 other long SP530 other long … and so on for 801 rows altogether. You may well wonder what benefit there is to working with an 801-row data frame rather than the simple tabulation in the original publication. First, giving the variables names allows us to distinguish between the variable being measured and the level of the measurement. Second, the table makes clear that both variables flower_color and pollen_shape are categorical. Third, suppose there was some other aspect being recorded about the plants, for instance the plant’s height or how much water the plant was given or the name of the technician who recorded the data. Using a data frame, these new variables can easily be added as additional columns. There’s no space in the tabulation for these additional measurements. A fourth reason to prefer the data-frame format for the genetics data is subtle. Most often, you will be using software to analyze data. Storing data in a consistent way – data frames – makes it much easier to use standard software than if the data are stored in a (pointless) variety of formats. 2.3 Quantitative and categorical variables The fundamental distinction to be made between types of variables is whether they are quantitative – a number – or categorical. Categorical variables are those where the possible values come from a set of discrete categories and are typically represented by text labels. In the Galton data (Figure 1), height is a quantitative variable. Sex is a categorical variable. The family variable has been encoded as a number, but it is not really numerical. For instance, with numbers, 2 is half way between 1 and 3. But family 2 is not “between” families 1 and 3 in any genuinely numerical sense. So family is a categorical variable. Much later in the book, we will translate categorical variables into a set of very simple numerical variables, each of which is called an indicator variable. In an indicator variable, the only allowed values are zero and one. Obviously, with just zero and one as possible values, a single indicator variable is not able to represent completely a categorical variable with three or more levels. In such situations, a set of indicator variables is used. If there are k different levels for the categorical variable, the equivalent set of indicator variables will have k - 1 members. For instance, a variable fruit with three levels “apple,” “blueberry,” and “cherry,” will correspond to two indicator variables. The first one might be whether the fruit is apple or not. The second would be whether the fruit is blueberry or not. When both the first and second take on the value zero, we know that the fruit must be the remaining level, cherry. Figure 5 shows the example on a case by case basis. fruit \\(\\rightarrow\\) indicator apple &amp; indicator blueberry cherry 0 0 apple 1 0 blueberry 0 1 apple 1 0 cherry 0 0 Figure 5: An example of how a categorical variable (‘fruit’) can be translated into simple indicator variables. Note that there is always at most a single 1 in each row of the table. 2.4 Response and explanatory variables Starting in Chapter 4, we will work with a standard format for reducing the potentially many rows and variables of a data frame into a single compact object: a statistical model. For our purposes, a statistical model will be a function that takes inputs and produces an output. In particular, the inputs to each statistical model will be the values of selected variables in the data frame generically called explanatory variables. The output of the statistical model will be in terms of the values of a single, selected variable generically called the response variable. The appropriate choice of a response variable and explanatory variables for a model depends on the question that you, the statistical investigator seek to address. Often, to address a broad question, you will use several different statistical models based on the same data frame. Once you have selected the response and explanatory variables (and a few other details) the process of constructing the corresponding statistical model is a matter of routine calculation, which is always automated. Many people find they can anticipate the results of the calculation for simple models by sketching the graph of a function on a plot of the variables. We delegate the “oppressive necessity” of the exact calculations to a computer, leaving our role to give the computer an order: “Fit the model to the data.” Keep in mind that response and explanatory variables are not types of variables, they are choices that we make in building a model. This not withstanding, in this book all models will have a response variable that is quantitative. If a categorical variable is to be involved in the response, it will have to be in the form of an indicator variable. On the other hand, explanatory variables can be either quantitative or categorical in any combination. References "],
["measuring-variation.html", "Chapter 3 Measuring variation 3.1 Variance of a numerical variable 3.2 Variance of a categorical variable?", " Chapter 3 Measuring variation Recall that the purpose of statistical inference is to determine which statistical claims are justified by the data on which they are based. This amounts to asking whether the data provide enough evidence to support a claim. How can we figure out how much data is enough? An obvious, and important way to quantify “how much” is the number of rows in the data frame, that is, the sample size \\(n\\). Perhaps it’s intuitive that more data constitutes more evidence. Some care is required here, since we want to avoid phony creation of large sample sizes by copying earlier rows to make new rows in the data frame. One proper procedure is to insist that each unit of analysis be grabbed at random from a population of all the possible units. A data frame constructed by such a procedure is called a sample of the population, which is why the number of rows \\(n\\) is called the sample size. It’s tempting to elaborate on how much evidence we have by counting the number of variables in the data frame. But there is a serious problem here. But there is no such thing as the “set of possible variables.” It’s the researcher who determines what will be a variable, and you can in principle make up as many as you like. In the running example from Chapter 1, the variables were age and running time. Sensible. But we might also have recorded the runner’s favorite number, or the time the runner’s brother had breakfast the Tuesday before the race, or anything else, relevant or not. Common sense tells you to avoid such silliness. But what one person considers silly might be sensible to someone else. For instance, many people take seriously astrological signs, but others don’t. Should we count astrological sign as a genuine variable? As it happens, birth month accounts for some of the observed differences in performance of professional athletes. (The reason appears to be that children who are the oldest in their school grade do better as kids in athletics, which leads to them developing confidence and interest in sports and receiving extra attention from coaches.) The key to measuring how much evidence the data provides lies in the sentence, “Birth month accounts for some of the observed differences in performance.” What matters is whether a variable can explain or account for the variation in a outcome of interest (like athletic performance). We need to be able to say how much variation is in the outcome. As described in the previous chapter, in a statistical model the outcome is represented by the response variable. We’ll measure the variation in the response variable and then compare it to the amount of variation that the statistical model attributes to the explanatory variable(s). 3.1 Variance of a numerical variable Recall that the statistical models we use in this book will always have a numerical response variable. We can quantify the amount of variation the response variable in many different ways. The conventional way is by a quantity called the variance. There are different ways to calculate the variance of a variable. Most textbooks give a formula that can be used efficiently by a computer. For the purpose of explaining the variance to another person, I like another way. The starting point is the response variable for which you want to know the variance. Usually, we organize variables into data frames, but for the moment imagine that the individual numbers, \\(n\\) of them, have been spilled out on the surface of a table. Take two of the numbers at random. Chances are, the two numbers are different but they might, by luck, be exactly the same. Doesn’t matter. To measure the variation of these two numbers, simply subtract one from the other to get the difference, then square the difference. Because of the squaring, it doesn’t matter whether you subtract the first number from the second or vice versa. For historical reasons, the variance is the square difference divided by two. But if history had worked out differently, the square difference would have been a fine measure of variation itself. The square difference measures the variation between two numbers. But we want to measure the variation of the whole set of numbers. To do this, repeat the calculation of the square difference for every possible pair of the numbers on the table. For instance, if there were \\(n=3\\) numbers, say \\[5, 9, 3\\] the pairs would be 5 - 9 giving a difference of -4 which squares to 16 5 - 3 giving a difference of 2, which squares to 4 3 - 9 giving a difference of -6, which squares to 36 Now average all the square differences. Averaging 16, 4, 36 gives 18.67. The variance, by historical convention, is half this number, or 9.33. When \\(n\\) is big, there are a lot of possible pairs of numbers. For instance, when \\(n = 100\\), there are 4950 pairs. That’s why we leave it to the computer to do the calculation, and even then the calculation is re-arranged so that there are only 100 square differences involved. If you like, you can think of the reason why we square the difference as a convenience to avoid having to worry about whether the difference is positive or negative (which depends only on which of the pair of values you put first in the subtraction). But there is some profound thinking behind the use of squares, which reflects the nature of randomness and, believe it or not, the Pythagorean theorem. 3.2 Variance of a categorical variable? A categorical variable has distinct levels, usually represented by labels such as agree, undecided, and disagree. To attempt to describe the amount of variation in a categorical variable we can follow the same process as for numerical variables: spill the collection of \\(n\\) labels onto a table, pick at random a pair of labels, subtract them, and square the difference. There’s a big problem, however. What is the numerical value of the difference between agree and undecided? How does the size of the difference between agree and undecided compare to the difference between disagree and undecided or between agree and disagree? Sometimes there’s a reasonable choice to be made, for example we might decide that agree and disagree differ by 2, agree and undecided differ by 1, and that disagree and undecided also differ by 1. Even more basic, it’s reasonable to say that the difference between agree and agree should be zero, and similarly for disagree versus disagree or undecided versus undecided. Notice that all these declared differences can be created by recoding the categorical variable as a numeric variable. For instance, we can change agree to 1, undecided to 2, and disagree to 3. Then just calculate the variance of the numerical variable in the usual way. Sometimes it’s sensible to translate the levels of a categorical variable into numbers. For instance, with agree/undecided/disagree it’s reasonable to think that undecided is inbetween agree and disagree. But, in general, there will be no such sense of inbetweenness of categorical levels. Take, for example, a categorical variable whose levels are the names of countries. Or a categorical variable whose levels are political parties: Green, Libertarian, Democratic, Republican. Which levels are between which? (As it happens, people do try to put political parties in sequential order by categorizing them on the scale from Left to Right.) Without a sense of inbetweenness of levels, it’s arbitrary to assign numbers to the various levels. Except in one situation. Often, categorical variables have only two levels. Yes or no. Dead or alive. Accepted or rejected. Treatment and control. Such variables are sometimes called binary (like the 0/1 of computer bits) or dicotomous or binomial (meaning, having two names) or even two-level. In the previous chapter, we called them indicator variables. When dealing with an indicator variable, there’s no level to be inbetween; there are only two levels and the idea of “in between” requires at least three distinct things. So we can easily agree, regardless of our opinions about how the world works, that the difference is zero between labels that are the same (say, yes and yes or between no and no). And when the labels are different (say, yes and no) we just need to assign a non-zero number to the difference. Which number? Should the square-difference between yes and no be 17, or 328, or 0.3? By convention, we use the number 1 for the square-difference between the two levels of a binary variable. This convention has the advantage of simplifying calculations. It’s also what you will get by treating indicator variables numerically. But there is another important advantage of the simple choice: any average of a 0/1 variable must always be somewhere in the range from 0 to 1, which is exactly the same scale we use for describing probability. The simplicity of dealing with indicator variables means that the techniques of statistical inference with an indicator for a categorical response variable are much easier than for non-binary categorical response variables. This is also the most common setting for classical inference. "],
["modeling-variation.html", "Chapter 4 Modeling variation 4.1 Statistical models 4.2 Quantitative response variables 4.3 Proportions and indicator variables 4.4 A taxonomy of simple models", " Chapter 4 Modeling variation The point of statistics is to understand how things vary. For instance, human height varies from one person to another. Some of that variation is associated with the sex of the person: women tend to be slightly shorter than men. Some of the variation in height relates to genes and genetic variation, some to differing nutrition and general health, etc. Statistical models attempt to use the variation in explanatory variables – sex, genetic traits – to account for the variation in a response variable. To offer a contemporary example, some automobiles are involved in fatal accidents and some (the vast majority, thankfully!) are not. It varies. What’s behind the variation? It could be the weather conditions at the time. It also be human driver fatique, inebriation, incompetence, distraction, etc. It could also be characteristics of the vehicle itself: size, weight, maneuverability, breaking power, physical wear, automatic breaking, etc. And a lot of the variation is a matter of chance: for instance, the arrival of another car at an intersection at a particular instant. 4.1 Statistical models For our purposes, a statistical model is a mathematical function that takes values of the explanatory variables as input and produces a corresponding output. For instance, a model of a person’s height might take the person’s age, sex, mother’s height and father’s height as inputs and give as output a specific number that we interpret as height. It might happen, by accident, that the model output is exactly on target for any particular person. More likely, though, the model output will be somewhat off: the person is somewhat shorter or taller than the model says. This is to be expected since the model can’t take into account every factor that influences height and because chance also plays a role. 4.2 Quantitative response variables Consider the model (and data) shown in Figure 4.1. These are Galton’s records on the heights of adult children in London families. In Figure 4.1, height has been selected as the response variable. To keep the example simple, the role of explanatory variable has been assigned to sex. The statistical model takes as input a level of sex and produces as output a numerical value for the response variable. Figure 4.1: Galton’s height measurements with height as the response variable and sex as the explanatory variable. The model gives a single output for each level of the explanatory variable. As you can see from Figure 4.1, the output of the model is about 64 inches when sex is F, and 69 inches when sex is M. How are the model outputs determined? Or, in other words, what method is used to construct the model? The details will be covered in the next chapter. For now, the primary point is that the kind of model being shown describes the center of the distribution of individuals. A secondary point is that the model methodology is standard and automatic; the model outputs were established strictly using sex as the explanatory variable without consideration of anything else and without room for a human to manipulate the numbers or shade them into a preferred direction. Galton was not directly interested in sex-related traits. His primary interest was in parent’s height as the explanatory variable. He recorded parent’s height quantitatively: a number. Figure 4.2 shows an example where the explanatory variable is numeric, as opposed Figure 4.1 which uses a categorical explanatory variable. The question that motivated Galton to collect the height data in the first place was to characterize the genetics of height: the extent to which it’s fair to say that a child inherits the height of his or her parents. Figure 4.2: Child’s height versus the mother’s height. A conventional form of model is a straight line. Consider first the model as a function. The input is the explanatory variable, mother’s height. The output is a number. So, for an input of 60 inches, the output is about 66 inches. For an input of 68 inches, the output is somewhat higher: about 68 inches. The model output describes the center of the distribution of adult-child heights. That center is somewhat lower among the children of relatively short mothers than it is among the children of relatively tall mothers. Note that hardly any individuals exactly match the model output generated when the input is set to their mother’s height; almost all are either shorter or taller. Some people mistakenly believe that the point of such a model is to predict the child’s height. Putting aside the question of why anyone would want to do this (perhaps you are wanting to buy a college graduation gown for your pregnant friend’s baby?), any meaningful prediction should be framed as an interval. So, for a 60-inch tall mother, a fair prediction would be for a child between 58 and 73 inches, while for a relatively tall 68-inch mother, the prediction would be 62 to 76 inches. There is so much overlap in the prediction intervals for children of mothers of very different height that the model tells us almost nothing about individuals. But this is not the purpose of the model. Galton’s objective in collecting the data was to say how much of the variation in height is attributable to genetics. The conventional measure of how much, introduced in Chapter 8, is that mother’s height accounts for about 4% of the variation in height among children. Note that it’s 4% of the variation in height among children, not 4% of the height of an individual child. Four percent doesn’t seem like much. Taking away the line in Figure 4.2 and looking just at the data points, you couldn’t fault someone for modeling the data with a level line, that is, one where the model output doesn’t change at all with mother’s height. One role of statistical inference is to answer the following question: Is there good reason to claim that the evidence provided by the data rule out a level-line model? 4.3 Proportions and indicator variables The previous examples involved models where the response variable is numeric. In this section, we look at the special case of the numerical response variable being an indicator variable. Recall that a single indicator variable can be used to encode a two-level categorical variable, for instance yes/no, alive/dead, succeed/fail, etc. To illustrate, consider some data from another approach to quantifying genetics by experimental manipulation. This tradition started with Gregor Mendel in the 1860s, who famously cross-bred peas. Students of genetics know the name Mendel. Another famous name is Reginald Punnett (as in the Punnett square), whose cross-breeding work was done around 1905. In one experiment, Punnett cross-bred sweet peas and observed the offspring’s flower color (binary levels white/other) and the shape of pollen granules (binary levels round/long). A few rows of data (translated to a modern format) from this experiment are shown in Figure 2.2 in Chapter 2. The complete data are graphed in Figure 4.3, below. Figure 4.3: Punnett’s data from cross breeding peas, along with a model of flower color versus pollen shape. There are only four possible combinations of white/other and long/round. To avoid plotting the rows directly on top of one another, the dots have been jittered. You can see that peas with “other” color and long pollen grains are the most common. The model here is very similar to that of Figure 4.1. The response variable, flower color, has been translated into an indicator variable taking on only the values zero or one. The model provides an output for each level of the explanatory variable, pollen shape. Notice that the model output is not set in terms of white/other, but as a number between zero and one. For models with an indicator response variable, the output is usually interpreted as a probability. For instance, when the pollen shape is long, the model output is 0.24. When the pollen is round, the model output is 0.25. We interpret a model output of 0.25–that is, 25%– as meaning that a quarter of the offspring will have white flowers. Comparing the model-output for long-pollen plants to that for round-pollen plants suggests that the probability of white flowers might be somewhat higher for round-pollen plants than long-pollen plants. The previous sentence uses some qualifying word: “suggests,” “might be,” “somewhat.” That’s to indicate that the statistical claim has not yet been vetted using the tools of statistical inference. You can pretty much draw functions like this by hand if you keep in mind some simple rules. First, the function has to stay as close to the data as possible. Second, the function has to stay centered on the data.2 It might help to understand the impact of these rules by comparing functions that do and don’t follow the rules. In Figures 4.3 and 4.4, the blue function follows the rules; the red ones do not. Figure 4.3: The red function is a bad match to the data. The large majority of points are far below the function. The blue function has the same form – a straight line – but is a legitimate match to the data, with data points more or less evenly balanced between being above and being below the blue line. Figure 4.4: The red function is a bad match to the data. At heights below 63 inches, almost all the data points are above the red line. Note that the blue functions in Figures 4.3 and 4.4 are centered in the sense that whatever value for the explanatory variable you look at, the data points are just about evenly distributed above and below the function. The red functions don’t accomplish this. 4.4 A taxonomy of simple models Recall that the response variables covered in this book are quantitative, which includes both regular numerical variables (like height) and indicator variables (like that for sex). Explanatory variables can be either quantitative or categorical. This suggests that models with one response and one explanatory variables fall into one of four types: Setting response variable explanatory variable Figure conventional name 1 quantitative categorical 4.1 groupwise means / t test 2 quantitative quantitative 4.2 linear regression / slope test 3 categorical (indicator) categorical 4.3 groupwise proportions / p test 4 categorical (indicator) quantitative 4.5 not usually included in introductory statistics Figures 4.1, 4.2, and 4.3 show the first three settings. Figure 4.5 shows the fourth setting, a categorical response variable and a numerical explanatory variable. Figure 4.5: A model with an indicator response variable and a numerical explanatory variable. Again, the model output is numeric, in the form of the probability that the child is female. The model suggests that 60-inch tall mothers are slightly less likely to bear girls and 68-inch tall mothers. Common sense suggests that a baby’s sex is not influenced by the mother’s height. Correspondingly, the model output is around 50% regardless of the mother’s height. Perhaps you’re surprised to see that there is any slope at all to the function. Don’t be surprised yet, because we haven’t shown that such a statement is justified by the data: we have a setting for inference but have not yet carried out the inference calculations to tell us if the statement is justified. For purposes of inference, conventional texts treat settings 1, 2, and 3 as different. (They don’t handle setting 4 at all.) I’ve added to the table the conventional name assigned to the different inferential tests in each setting. But in all settings, exactly the same technique, called linear regression, has been used to match the model to the data.3 In this book, rather than introduce four different inferential procedures, we’ll have just one. That’s a major factor behind the ability to describe classical inference concisely. "],
["model-values.html", "Chapter 5 Model values 5.1 Model fitting: A contest between candidate models 5.2 Variance of model values", " Chapter 5 Model values It’s now time to talk a bit about the way that statistical models are constructed. To do this, imagine that we have a classroom full of students, each of whom is given data in the form of the graphs of the previous chapter and asked to draw a straight-line function relating the explanatory variable to the response variable. Naturally, some students’ models will be better than others. How can we determine which model is the best? 5.1 Model fitting: A contest between candidate models To illustrate, let’s take a small data set and look at two models that students might draw. (Figure 5.1) Figure 5.1: Two candidates for straight-line models of a handful of data points. Who has drawn the better model: Linus or Curly? The instructor takes out a blue pen and draws a * for every data point, as in Figure 5.2. The star marks the output of the model when given the input (mother’s height) for that point. The position of each * on the vertical axis marks the model value for that data point. Figure 5.2: Applying the model function (blue line) to the values of the explanatory variable (mother’s height, on the horizontal axis) produces the model values, marked with a \\(\\star\\).. Think of the model values as a kind of stand-in for the response variable, one that stays strictly in line with the model. Now to determine whether Linus or Curly has the better model. The instructor takes out her red pen to mark the “error,” as in Figure 5.3. The error (marked as a red line) is the difference between the actual value of the response variable (vertical position of black dot) and the model value (blue \\(\\star\\)). Figure 5.3: The model error for each data point (shown as red line segments) is the distance between the response value (vertical position of black dot) and the corresponding model value (blue \\(\\star\\)). The magnitude of the error is the length of the red line. In statistics, model candidates are graded according to the sum of square errorsk, as in Figure 5.4. (There is a good reason for this, analogous to the Pythagorean Theorem for the sides of a right triangle, but that needn’t concern us here.) So Linus’s and Curly’s models are graded according to the total amount of red ink used in drawing the squares. Figure 5.4: Each candidate model is given a grade that is the sum of the square errors, represented here by the total amount of red ink. The less red ink, the better. Linus wins. The process of constructing a statistical model reflects the contest just described between Linus and Curly and the judgement made by the teacher. But rather than looking at just two candidates, grades are assigned to a very large set of candidate models. Once the explanatory and response variables have been selected, and a shape for the function chosen (here, a straight line), the computer tries out all the possibilities and picks the one that gives the least error between the model values and the actual response values. In practice, for straight-line models (and more general forms, called “linear models”), there are equations that can be solved to find the best model, so there’s no need for the computer to try out lots of candidates. But the result is no different than if it had been found by trial and error. 5.2 Variance of model values There is something important to notice about the model values for the winning model: Model values will have a lower variance than the response variable. We’ll use the symbol \\(v_m\\) to stand for the variance of the model values. To illustrate this, let’s look at a couple of models from the previous chapter. In each, you can see that the response values (black dots) are spread out, while the model values stay in toward the center of data. This is a natural consequence of our using central models, that is, models where the function has roughly equal numbers of data points above it and below it. Figure 5.5: Model values (blue dots) for a straight-line model of child’s height with mother’s height as the explanatory variable. Response variance: 12.84; Model value variance: 0.52 Figure 5.6: Model values for the probability that a pea has a flower colored white, with pollen shape as the explanatory variable. Response variance: 0.17; Model value variance: 0.000091 Figure 5.7: Model values for a model of sex, with mother’s height as the explanatory variable. Response variance: 0.25; Model value variance: 0.14 "],
["degrees-of-flexibility.html", "Chapter 6 Degrees of flexibility 6.1 One degree of flexibility 6.2 Multiple degrees of flexibility 6.3 Covariates 6.4 Flexibility, literally 6.5 Degrees of flexibility and freedom", " Chapter 6 Degrees of flexibility \\(\\newcommand{\\flex}[]{^\\circ\\!{\\cal{F}}}\\) Chapter 4 introduced four different settings for models. (For easy reference, Figure 6.1 redraws the examples from Chapter 4.) Remember that the word “settings” is not about the situation that produced the data or the names of the variables being displayed. “Settings” refers to the kind of response variable and explanatory variable – categorical or numerical – begin used in the model. This chapter introduces some important new settings: Settings with more than one explanatory variable Settings where a categorical explanatory variable has more than two levels. Settings where the straight-line functions seen in Figure 1(b) and 1(d) are replaced with more flexible curves. It’s far from obvious, but these new kinds of settings are all the same kind of thing mathematically, so statistical inference can handle them in the same way. The central concept that links the new settings is called the degrees of flexibility. For brevity, I’ll use symbols rather than the whole phrase “degrees of flexibility,” a degree sign followed by a flexible-looking F, that is: \\(\\flex\\). 6.1 One degree of flexibility Each of the models presented in Chapter 4 has a single degree of flexibility, that is, \\(\\flex = 1\\). You can think about degrees of flexibility as how many numbers are required to specify the model completely. For instance, the straight-line models in Figure 6.1(b) and 6.1(d) each can be specified by a slope and an intercept. The models in Figure 6.1(a) and 6.1(b) can be specified by two numbers: the value of the model for the left group and the value for the right group. Figure 6.1: Four settings for modeling presented in Chapter 4. All of these have one degree of flexibility, written \\(\\flex=1\\). In talking about descriptions of models, rather than using the word number, we use coefficient. This is no big deal, but when you see the word coefficient you’ll have a distinct hint that we are talking about the shape of a model. And we’ll be able to say things like “the number of coefficients” to refer to how many coefficients are needed to specify the model. The degree of flexibility of a model is defined to be the number of coefficients needed to completely specify the model minus one. You might wonder, “Why subtract one from the number of coefficients?” Just a convention. You’ll see some justification for it in Chapter 8, Simple means and proportions, where we will work with models with zero degrees of freedom, which is to say, one coefficient. 6.2 Multiple degrees of flexibility Let’s look at some examples of models where there is more than one degree of freedom. To start, Figure 2 shows a model with two degrees of freedom: \\(\\flex = 2\\). Three coefficients are needed to specify the model values for a model where the 3-level categorical variable Species is the explanatory variable. The data in Figure 2 are from a classic study involving the differences and similarities among three species of iris plants. The response variable is the flower petal width (quantitative) and the explanatory variable is the species of the plant (categorical). A complete description of the model would involve three coefficients, one for each of the species of iris. Three coefficients corresponds to \\(\\flex = 2\\). If the explanatory variable had four levels, there would be \\(\\flex=3\\), and so on. There’s just a single explanatory variable in Figure 2 (albeit one with three categorical levels). Many models have more than one explanatory variable. Figure 3 shows an example, where the response variable is height and bother mother’s height and child’s sex are being used as explanatory variables. The model in Figure 3 consists of two straight lines. Each line is specified by a slope and an intercept, meaning that four coefficients are needed. Thus, \\(\\flex=3\\). You may notice that the two lines in Figure 3 have slightly different slopes. Often, modelers try to economize with degrees of flexibility by using the same slope for each line. This would reduce the degrees of freedom to \\(\\flex = 2\\). (The decision of whether to use a common slope or two potentially different slopes is often made using the tools of statistical inference, but we are getting ahead of the story.) Figure 3: A model of height with two explanatory variables: the mother’s height and the child’s sex. Each explanatory variable added to a model makes it possible for the model more faithfully to reproduce the response variable. 6.3 Covariates This is a good time to introduce an important concept in statistical modeling. It doesn’t have directly to do with the mechanics of statistical inference, but it is critical to interpreting models with multiple explanatory variables. Often, there is particular interest in the relationship between two variables. Galton’s interest was in the relationship between the parents’ height and the child’s height. There may be other factors involved in the system – with height a major factor is the sex of the child, but there could be others such as nutrition, health, etc. Common sense suggests holding these other factors constant so that you can look specifically at the single explanatory variable of particular interest. In the 1880s, Galton did this by considering only the heights of boys rather than the heights of all children. Within a few years of Galton’s work, statisticians had developed techniques to build models with multiple explanatory variables, like Figure 3, which broadened the notion of “holding other factors constant” to include accounting for those factors in a model. The factors that the modeler wants to hold constant are called covariates. Really this is just a name for an explanatory variable which is not of direct interest to the modeler but which the modeler thinks might be playing a role in the system and can’t be ignored. It takes just the most basic notion of biology to realize that when it comes to the relationship between mother’s and child’s height another potentially important covariate is the height of the father. Figure 4 shows two such models. The model in 4(a) was constructed to have 3 degrees of freedom; 4(b) has 7 degrees of freedom. Figure 4. Two models of child’s height versus mother’s height. Father’s height and child’s sex are included as explanatory variables. Although father’s height is a quantitative variable, the graph shows the model for only three, evenly spaced, discrete values. Comparing the two models, you might see how a larger \\(\\flex\\) corresponds to increased flexibility. You might also note from Figure 4 that the model with 8 degrees of freedom suggests that the taller is that father, the more influence the mother has on child’s height. The methods of statistical inference let us examine whether this claim is actually justified. 6.4 Flexibility, literally Chapter 5 imagined a contest between two students, Linus and Curly, for the best model. Let’s return to that example, but now we’ll construct some models that are more flexible than a straight line. Figure 5: (a) a flat model – zero degrees of flexibility, \\(\\flex=0\\); (b) a straight-line model – one degree of flexibility, \\(\\flex = 1\\); (c) a model with one bend – two degrees of flexibility, \\(\\flex = 2\\); (d) a model with two bends – three degrees of flexibility, \\(\\flex = 3\\). In the models in Figure 5, the degrees of flexibility indicate the shape of the function. A flat line has no degrees of flexibility. A sloped line has one degree of flexibility. Adding a bend adds another degree of flexibility, so 3 degrees of flexibility corresponds to two bends. Notice that as the degree of flexibility goes up, the model function gets closer to the data points. Correspondingly, the variance of the model values, \\(v_m\\), goes up with increasing degrees of flexibility. The point of counting degrees of flexibility is to be able to adjust \\(v_m\\) to take into account the intrinsic nature of flexibility to match more closely the response values. For sufficiently high degrees of flexibility, a model will be able almost perfectly to reproduce the response variable, even when there is no relationship between the response and explanatory variables. 6.5 Degrees of flexibility and freedom The term “degrees of flexibility” is not at all conventional in statistics. I like “flexibility” because it gets at how curvy and complex and multivariate a model is. Flexibility is about the model itself. But the tradition in statistics is to use a quantity called the “degrees of freedom”–often written df–which takes into consideration the sample size \\(n\\). There is a very close relationship between df and \\(\\flex\\): \\[\\mbox{df} \\equiv n - (1 + \\flex) .\\] I might just as well have written this book using df instead of \\(\\flex\\), but I want to encourage you to think about how much flexibility a model has to help it get close to the data. For me, the sample size \\(n\\) plays a different role, as you’ll see in the next chapter. "],
["effect-size.html", "Chapter 7 Effect size 7.1 With respect to … 7.2 Slopes and differences 7.3 Risk 7.4 Simple changes in input 7.5 Reading effect size from a graph", " Chapter 7 Effect size An effect size tells how the output of a model changes when a simple change is made to the input. Many statistical claims are made in terms of an effect size. For instance, according to the US National Highway Traffic Safety Administration (NHTSA), wearing seat belts reduces the risk of fatal injury to passenger-vehicle occupants by about 58%. (Kahane 2017) This is an effect size. In contrast, this related fact from NHTSA is not an effect size: 51% of male passenger-vehicle occupants killed in 2017 were not wearing seat belts. An effect size summarizes a comparison between two different conditions. In the first example, those two conditions are 1) wearing a seat belt and 2) not wearing a seat belt. In the second example, however, there is just one condition: being a male passenger-vehicle occupant who died in a car accident in 2017. 7.1 With respect to … Effect sizes always involve two variables: a response variable and a single explanatory variable. Effect size is always about a model. The model might have one explanatory variable or many explanatory variables. Each explanatory variable will have its own effect size, so a model with multiple explanatory variables will have multiple effect sizes. We use the phrase “with respect to” indicate which explanatory variable is involved in an effect size. For instance, in the previous example, the response variable is “risk of fatal injury” and the explanatory variable records whether the vehicle occupant was wearing a seat belt. So we would call the quoted 58% the “effect size on risk of fatal injury with respect to wearing seat belts.” Depending on the purpose of your work, you may want or need to include other explanatory variables in your model. For instance, the NHTSA gives a “safety star rating” to each year-make-model of vehicle. If this were included in the risk-of-fatal-injury statistical model, there will be an effect size of “risk of fatal injury with respect to safety-star rating.” Other explanatory variables might be speed of the vehicle at the time of the accident (though this can be difficult to measure), weight of the vehicle, the index of traction/slipperiness of the road surface, and so on. Depending on the variable selected to play the role of “with respect to,” an effect size can serve very different purposes. For instance, the quoted 50% reduction in risk of fatal accident with respect to wearing a seat belt, provides a good argument for wearing seat belts. The effect size of risk of fatal accident with respect to safety-star index could help people shopping for a car. It would also give an concrete sense of whether the difference between a four- and a five-star vehicle is substantial or trivial. 7.2 Slopes and differences Consider two models introduced in Chapter 5. Figure 5.1 shows child’s height versus mother’s height in Galton’s data. The straight-line model shows a slight upward slope. To calculate the effect size of child’s height with respect to mother’s height, pick two values of mother’s height: say 60 and 68 inches. From the graph you can read the output of the model at these two values of the input. At an input of 60 inches, the output is 65.5 inches. At an input of 68 inches, the output is (coincidentally) 68 inches. The effect size is the slope of the model: rise over run. Here, the “run” is 68 - 60 = 8 inches. The “rise” is 68 - 65.5 = 2.5 inches. So the slope is 2.5 / 8 = 0.31. The model in Figure 5.1 has a quantitative explanatory variable: mother’s height. In constrast, the model in Figure 5.2 has a categorical explanatory variable: pollen shape. To calculate an effect size with respect to pollen shape in Figure 5.2, follow much the same procedure. First, pick the two input levels you want to compare. Here, there are only two levels possible: long and round shapes. Next, look up the model output at each of the two inputs. The output of the model is framed as a probability. The probability of a white flower is 24% for long pollen, and 25% for round pollen. Since the explanatory variable is a categorical variable, it doesn’t mean much to look at the numerical difference in the input. The model output, on the other hand, is quantitative (as it is for all the models we consider in this book). The effect size is 25% - 24% = 1 percentage point. To recap, when the explanatory variable is quantitative, the effect size is stated as a slope: change in output divided by change in input. When the explanatory variable is categorical, the effect size can be stated as a difference. In this situation, it’s important to say which way the effect goes. For instance, the NHTSA risk of fatal injury with respect to wearing a seat belt was described as a reduction in risk when wearing a seat belt compared to not wearing one. 7.3 Risk In the previous paragraph, I say “can be stated as a difference” because there are other ways often used to compare the model output between two different levels of a categorical explanatory variable. For instance, when the output is interpreted as a “risk,” the two outputs might be compared as a ratio, called the risk ratio. It sounds odd when talking about flower color, but if we were thinking about the “risk” that a pea plant’s flowers are white, then it would be appropriate to consider the effect size with respect to pollen shape as the ratio 25% / 24% = 1.04. Note that this 1.04 is not in percent. When writing about risk ratios, people often use percentage terms. The risk ratio of 1.04 might be described, “The risk of a white flower increases by 4 percent.” Were the risk ratio smaller than 1, say 0.87, we would speak of a risk decrease: “The risk of a white flower is 13% lower for ….” It’s potentially confusing for us to report differences of risk in “percentage points” and ratios of risk as “percent.” Not everyone is sensitive to the distinction between “percentage points” and “percent.” Perhaps it would be helpful to report differences as an absolute change in risk while ratios are a relative change in risk. There’s yet another way used to describe changes in risk: the odds ratio. Odds are a different format for describing risk. If the probability of an outcome is \\(p\\), the odds are \\(p/(1-p)\\). So, the odds of a white flower in a plant which has round pollen is \\(0.25/(1-0.25) = 0.25 / 0.75 = 1/3\\). The use of odds, and its cousin, log odds, is a genuine help when working with models with multiple explanatory variables. 7.4 Simple changes in input I’m using the word “simple” to refer to the change in input involved in an effect size. Several considerations motivate this: When looking at a categorical explanatory variable, an effect size is a comparison of just two of the levels. When looking at a quantitative explanatory variable, I advocate using a finite change in input, e.g. the 60 inches to 68 inches in mother’s height. That’s simpler than the alternative, using an infinitesimal change in input, and more appropriate for many machine-learning models where the output can vary discontinuously as the input changes. But the main thing I want to emphasize with the word “simple” has to do with models with multiple explanatory variables. In such models, there are different effect sizes for the different explanatory variables. That is, an effect size reports the change in model output when a single one of the explanatory variables is changed, holding all the others constant. This is where the phrase “with respect to” comes into play. For instance, the model displayed in Figure 6.4, with child’s height as the response variable, involves three explanatory variables: mother’s height, father’s height, and child’s sex. An effect size in such a model refers to a specific explanatory variable. So it’s meaningful to speak of the effect (on child’s height) with respect to mother’s height, or the effect with respect to father’s height, or the effect with respect to child’s sex. Which one is right for you depends on what you are investigating. 7.5 Reading effect size from a graph Chapter 6 introduced four simple settings for statistical inference that are at the core of conventional statistics books. In every setting, the response variable is quantitative. The single explanatory variable is either categorical (as in Figure 6.1(a) or quantitative (as in Figure 6.1(b)). For convenience, I’ll repeat those two figures here, with some annotation to show how to calculate the effect size. Figure 7.1: A reproduction of Figure 6.1(a) with annotations to show the effect size. The model in Figure 6.1 is height as a function of sex. The model values are marked as blue lines: 64.1 inches for “F” and 69.2 inches for “M”. Changing the input from F to M therefore brings about a change of \\(69.2 - 64.1 = 5.1\\) inches. Since the explanatory variable is categorical, the effect size with respect to sex (“F” \\(\\rightarrow\\) “M”) is 5.1 inches. Less stilted language would be, “Men tend to be 5.1 inches taller than women.” But watch out. The “men tend to be …” statement is easily interpreted as being about men and women. In fact, as you can see from the dots in the graph, many women are taller than many men. Keep in mind that the 5.1 inches is an effect size. When the explanatory variable is quantitative, the effect size is presented as a slope. To calculate the slope, select two different values of the explanatory variable, as with the ones marked with vertical lines in Figure 7.2 below. Figure 7.2: A reproduction of Figure 6.1(b) with annotations to show the effect size. The two values selected for the explanatory variable (mother’s height) are 60 and 68 inches, so the run is 8 inches. For an input of 60 inches the model output is 65.5 inches. For an input of 68 inches, the model output is 68.0 inches. thus, the run is 2.5 inches. The effect size is the ratio of rise to run: 2.5 inches / 8 inches = 0.31. References "],
["f-and-r.html", "Chapter 8 F and R 8.1 The F statistic 8.2 What’s the meaning of F? 8.3 R-squared 8.4 F in statistics books 8.5 Another explanation of F", " Chapter 8 F and R \\(\\newcommand{\\flex}[]{^\\circ\\!{\\cal{F}}}\\) We now have the pieces we need to assemble the central quantity which informs statistical inference. These are: \\(n\\), the sample size (or, more concretely, the number of rows in out data frame) \\(v_r\\), the variance of the response variable. \\(v_r\\) for binary categorical response variables is based on the 0-1 encoding. \\(v_m\\), the variance of the model values. \\(\\flex\\), the degree of flexibility.4 We’ll put these together to form a quantity called F. 8.1 The F statistic The name, F, is in honor of Ronald Fisher, one of the leading statisticians of the first half of the 20th. The formula for F is pretty simple, so I’ll present it right here for ready reference. \\[F \\equiv \\frac{n - (1 + \\flex)}{\\flex} \\frac{v_m}{v_r - v_m}\\] For almost all the settings considered in introductory statistics courses, \\(\\flex\\) is 1, so the formula simplifies to: \\[F = (n-2) \\frac{v_m}{v_r - v_m}\\] Example: Figure 4.1 shows a model of child’s height with respect to sex. The variance of the response variable (child’s height) is \\(v_r =\\) 12.84 inches2. The variance of the model values is \\(v_m =\\) 6.55 inches2. The data used to construct the model have \\(n = 898\\), giving \\[F = 896 \\frac{6.55}{12.84-6.55} \\approx 897 \\times 1.04 \\approx 934 .\\] 8.2 What’s the meaning of F? F combines the four quantities \\(n\\), \\(v_r\\), \\(v_m\\), and \\(\\flex\\). To get a notion why the combination works, keep these basic ideas in mind concerning what it means to have “more evidence.” The larger \\(n\\), the more evidence. That’s why F is more-or-less proportional to \\(n\\). (Strictly speaking, F is proportional to \\(n - (\\flex + 1)\\).) The more complicated the model – e.g. the number of explanatory variables or levels in an explanatory categorical variable – the less evidence. Or, put another way, we would want more evidence from data to justify a complicated model than a simple model. The division by \\(\\flex\\) in the formula for F implements this idea. The closer the model values come to capturing the actual response variable, the greater the evidence that there is a relationship. An obvious way to quantify this closeness are with the difference \\(v_r - v_m\\). We want the size of F to increase as \\(v_m\\) gets closer to \\(v_r\\). So F is proportional to \\(\\frac{1}{v_r - v_m}\\). But the numerical value of the difference \\(v_r - v_m\\) depends on the units in which the response variable is measured. For instance, we could express the running times in Chapter 1 in minutes or in seconds. But the difference \\(v_r - v_m\\) would be \\(60^2 = 3600\\) times larger if we used seconds than minutes. Obviously we don’t want our F value to depend on the units used. To avoid that, we divide \\(v_r - v_m\\) by \\(v_m\\), getting the \\(v_m / (v_r - v_m)\\) in the formula for F. 8.3 R-squared Many people prefer to look at a ratio \\(v_m / v_r\\) to quantify how close the model values are to the values of the response variable. If the model does a good job accounting for the response variable, then \\(v_m\\) will be close to \\(v_r\\). That is, the ratio will be close to 1. On the other hand, if the model tells us little or nothing about the response variable, \\(v_m\\) will be close to zero and the ratio itself will be zero. The ratio has a famous name: R-squared, that is: \\[R^2 = v_m / v_r\\] A more obscure name for \\(R^2\\) is coefficient of determination, which is awkward but does express the point that \\(R^2\\) is about the extent to which the explanatory variables, when passed through the model, determine the response variable. \\(R^2\\) is, literally, the faction of the variance of the response variable that has been captured by the model. \\(R^2\\) can never be bigger than one and can never be negative. When \\(R^2 = 1\\), the model values are exactly the same as the values of the response variable. When there is no connection between the r esponse and explanatory variables, \\(R^2\\) will be small. Ideally, it would be zero, but the process of random sampling generally pushes it a little away from zero. One way to think about F is as indicating when there is so little data that a small but non-zero R2 is consistent with the hypothesis that there is no connection between the response and explanatory variables. Example: Figure 4.1 shows a model of child’s height with respect to sex. The variance of the response variable (child’s height) is 12.84 inches2. The variance of the model values is 6.55 inches2. Thus: \\[R^2 = 6.55 / 12.84 = 0.51 = 51\\%\\] 8.4 F in statistics books In most statistics book, F is not written in the form above but in one of a couple of alternative – but equivalent – forms. There’s no particular reason to use these forms. Knowing what they look like will help you make sense of traditional statistical reports. Since \\(R^2\\) summarizes the relationship between \\(v_m\\) and \\(v_r\\), the formula for F can be written in terms of \\(R^2\\). This is the first of the alternative forms. \\[F = \\frac{n - (\\flex+1)}{\\flex} \\frac{R^2}{1 - R^2}\\] Another alternative form comes from using an intermediate in the calculation of \\(v_m\\) and \\(v_r\\). Recall how the variance is calculated by calculating square differences and averaging. To average, of course, you add together the quantities and then divide by the number of quantities being averaged. Suppose you didn’t bother to average, and stopped after adding up the square differences. The name for this intermediate is the sum of squares. F is often written in terms of the sum of squares of the response variable SS_r_ and of the model values SS_m_. Something like this: \\[F = \\frac{n - (\\flex+1)}{\\flex} \\frac{\\mbox{SS}_m}{\\mbox{SS}_r - \\mbox{SS}_m}\\] More typically, instead instead of looking at the model values directly, the tradition in classical inference is to consider what’s called the sum of squares of the residuals, which is simply SSR = \\(\\mbox{SS}_r - \\mbox{SS}_m\\) and the formula is re-written like this: \\[F = \\frac{\\mbox{SS}_m / \\flex}{SSR / (n - (\\flex + 1))}.\\] Both the numerator and the denominator of this ratio have the form of a sum of squares divided by a count. In the terminology of classical inference, such things are called mean squares. In this book, we’ll just use the formula for F given at the start of this chapter. The others give exactly the same value, but let’s avoid having ton work with potentially confusing vocabulary such as the mean square and sum of squares. 8.5 Another explanation of F First, I’ll give the explanation in the form of a parable. Imagine that your model is a automobile. You are going to drive it a distance of 100 miles. There are two gas companies, EXPLANATORY Fuel and RANDOM Fuel. You put in 2 liters of EXPLANATORY gas and drive as far as you can get, say 44 miles. Your fuel economy on the EXPLANATORY part of the trip is thus 22 miles per liter. You’re out of fuel, but conveniently there is a RANDOM gas station close at hand. You fill up your tank with RANDOM gas and continue driving. You drive the rest of the way using the random gas. Looking at the fuel gauge, you see that you have used up 8 liters of RANDOM gas, the fuel economy is 56 miles (that is, 100-44) per 8 liters of RANDOM gas, so the fuel economy is only 7 miles per gallon of RANDOM gas. Now a skeptic asks you, “The EXPLANATORY gas company has a good name for marketing, but do you have any good reason to think that EXPLANATORY gas is better than RANDOM gas?” Of course, the answer is yes, but how to summarize your findings? One way is to compare the fuel economies of the different kinds of gas: 22 miles per gallon for EXPLANATORY and 7 for RANDOM. More concisely, you could say that EXPLANATORY gas is more than 3 times (22/7) as efficient as RANDOM gas. The miles travelled using EXPLANATORY gas corresponds to R2. The fuel itself is whatever explanatory variables (and nonlinearities and whatever) are in your model. The amount of EXPLANATORY gas is \\(\\flex\\). RANDOM gas is not manufactured from genuine explanatory variables. Instead it is synthesized purely from random numbers. You don’t expect RANDOM gas to be very good. But it serves as a point of comparison for the effectiveness of EXPLANATORY gas. To conduct the comparison, you’ll look at the ratio of the fuel economies: EXPLANATORY fuel economy divided by RANDOM fuel economy. That ratio of fuel economies corresponds exactly to F. Perhaps you’re thinking, “RANDOM gas won’t get you anywhere.” That’s not true. You can confirm this by creating a dataset that consists only of random numbers then modeling one of the variables by the others. You’ll find that R2 is not zero. Indeed, if you use \\(n-1\\) random explanatory variables in your model, you’re guaranteed to reach \\(\\mbox{R}^2 = 1\\). Figure 6.13 shows simulations of R2 versus \\(\\flex\\) for RANDOM gas. (Not every gallon of RANDOM gas is the same, it’s random!) (ref:R-path-cap) Figure 6.13: The dark path shows one trial in which the car is fueled entirely with RANDOM gas. The graph shows how far the car gets (in terms of R2) as it uses more and more fuel (in terms of \\(\\flex\\)). Figure 8.1: (ref:R-path-cap) Figure 6.14 shows schematically the general form of distance R2 versus fuel consumption when the first 10 units of fuel (that is to say, \\(\\flex = 10\\)) are EXPLANATORY gas. As you can see, the EXPLANATORY gas got you to R2 = 65%. So the fuel economy for EXPLANATORY gas is about 6.5% per unit of fuel. Figure 8.2: Figure 6.14: \\(\\mbox{R}^2\\) versus \\(\\flex\\). For the first 10 units of fuel, EXPLANATORY gas was used. Then the car switched over to RANDOM fuel for the rest of the journey to \\(\\mbox{R}^2 = 1\\). Note that the path upward to the blue dot (using EXPLANATORY gas) is much steeper than for the rest of the journey using RANDOM gas. The slope of each segment is the fuel economy. With enough RANDOM gas, you’ll get the rest of the way to R2 = 100%. How much is enough? \\(n - (\\flex + 1)\\) units of fuel. Since \\(n=50\\) and \\(\\flex = 10\\), the RANDOM gas fuel economy is 35% (that is, 100% - 65%) divided by 39, or just under 1% per unit of fuel. The F statistic is therefore 6.5% / 1% = 6.5. Is 6.5 a big enough F to convince us that the EXPLANATORY gas is clearly not just RANDOM gas in disguise? We can find that out by doing a simulation where we use only RANDOM gas in the car, comparing how far we get with the first \\(\\flex = 10\\) liters to how much addition RANDOM fuel to get to our eventual destination of R2 = 100%. That’s what Figure 6.13 is about. You can mark on any of those random paths the value of R2 reached with the first \\(\\flex = 10\\) liters of fuel. Then draw in the equivalent of the blue slope and the red slope. For the large majority of trials, the ratio of slopes will be less than 4. So \\(F = 6.5\\) is not a plausible outcome when using only RANDOM fuel in the car. Note the expression for F in terms of R2: \\[F \\equiv \\frac{\\mbox{R}^2}{\\flex} \\div \\frac{1 - \\mbox{R}^2}{n - (\\flex + 1)}\\] The first ratio in the above is the slope of the blue line segment in Figure 6.14. The second ratio in the above is the slope of the red line segment in Figure 6.14. "],
["confidence-intervals.html", "Chapter 9 Confidence intervals 9.1 Calculating confidence intervals on effect size 9.2 4 and 95% 9.3 4 and \\(n\\) 9.4 Confidence versus prediction intervals 9.5 For the conventionally trained reader …", " Chapter 9 Confidence intervals \\(\\newcommand{\\flex}[]{^\\circ\\!{\\cal{F}}}\\) Chapter 7 started with an example of an effect size: the reduction in risk of fatal injury of vehicle occupants with respect to wearing a seat belt. That reduction is pretty impressive: about 58% according to a report (Kahane 2017) from the US National Highway Traffic Safety Administration (NHTSA). This chapter deals with the word “about” in the previous sentence. “About” is a statement about the precision of the effect size: how well we know it. It’s natural–but wrong–to assume that the precision can be sorted out from the effect size itself. For 58%, common sense suggests that about means something like “in the range from 56% to 60%.” In fact, the report (Kahane 2017) explicitly states the precision as 41% to 69%. The format of this statement is an interval, the “confidence interval” on the effect size of risk reduction with respect to wearing a seat belt. 9.1 Calculating confidence intervals on effect size Conventional textbooks have dozens of pages covering the calculation of confidence intervals for the four settings introduced in Chapter 4. Each of those settings involves a single explanatory variable and \\(\\flex = 1\\). We can simplify a bit. The steps are: Find the effect size itself, using the techniques in Chapter 7. We’ll call the effect size B and it will be a slope or a difference depending on whether the explanatory variable is quantitative or categorical. Find the F statistic for the model. Calculate the confidence interval (CI) on the effect size. Being an interval, a confidence interval is a range of values delimited by a lower and upper bound. But it’s common to display the interval using plus-or-minus \\(\\pm\\) notation. In \\(\\pm\\) notation, the confidence interval on the effect size is written \\[\\mbox{B} \\pm \\mbox{margin of error}\\] We already know B. The margin of error has a very simple formula involve both B and F: \\[\\mbox{margin of error} = \\mbox{B}\\sqrt{4 / \\mbox{F}}.\\] Example: For the model shown in Figure 7.1, the effect with respect to sex of child’s height is found to be \\(B = 5.1\\) inches. The F statistic is 933. So the margin of error on the effect size is \\[5.1\\ \\mbox{inches}\\sqrt{4/933}\\ \\ \\ \\approx\\ \\ 0.33\\ \\mbox{inches}\\] Correspondingly the confidence interval will be: \\(5.1 \\pm 0.33\\) inches, or, 4.77 to 5.43 inches Example: For the model shown in Figure 7.2, the effect of child’s height with respect to mother’s height is found to be B = 0.31. The F statistic is 34. So the margin of error is \\[\\mbox{margin of error} = 0.31 \\sqrt{4/34}) \\approx 0.11\\] The confidence interval itself is \\[0.31 \\pm 0.11\\ \\ \\ \\mbox{or}\\ \\ \\ 0.20\\ \\mbox{to}\\ 0.42\\] This simple method for finding the confidence interval on an effect size works only when \\(\\flex = 1\\). For models with multiple explanatory variables, confidence intervals can be calculated, but not with this simple formula. A formula can be expressed using concepts from linear algebra, but in practice everyone relies on statistical software to do the calculations. 9.2 4 and 95% The confidence intervals described above are called “95% confidence intervals.” The 95% is called the “confidence level.” A precisely mathematical interpretation of that 95% is difficult for many people to follow and easy to get wrong.5 It suffices to say two things: 95% is the conventional confidence level, so use it. It’s common to hear this interpretation of the 95% confidence interval: “95% of the time, the true value of the effect size will be inside the interval.” This is not exactly right, in part because we would need to know what “true” means in order to operationalize the statement. But, even if the interpretation is not right, it gives a reasonable impression of the intent behind a 95% confidence interval. There is a small group of people who need to figure out how to calculate confidence intervals. For these people, it’s important to know exactly what a confidence interval is intended to mean. You’ll see the play out in the following explanation, which attempts to show how we know the formula for the CI produces an interval at a 95% confidence level. Notice that in the formula for the 95% margin of error on the effect size \\[\\mbox{margin of error} = B \\sqrt{4/F}\\] the number 95% does not directly appear. What is it about this formula that makes the margin of error at a 95% confidence level rather than some other level? It is the number 4, which can be seen as the result of an experiment. Here’s the experiment. Make some data where the variables are composed entirely of random numbers. It doesn’t really matter what the sample size \\(n\\) is. For now, let’s assume \\(n \\gtrapprox 25.\\) Pick one of the variables as a response–it doesn’t matter which one. Then pick others as the explanatory variables–again, it doesn’t matter much which ones or how many. Let’s say you use \\(\\flex\\) of them, where you get to choose \\(\\flex\\). Since we are making up the data, we know exactly the mechanism that is generating it, so we are in a good position to say what’s “true” about the mechanism. Since the response and every explanatory variable are random, the “true” effect size with respect to any of the explanatory variables is zero. Now construct a model of the response variable as a function of the explanatory variables, find the variance \\(v_r\\) of the response variable and the variance \\(v_m\\) of the model values. Use these along with \\(n\\) and \\(\\flex\\) to find the F for the model. Since there is no connection between the response and the explanatory variables, we expect F to be small. Indeed, the typical F found by such an experiment is the very definition of “small” for F. Small F means that the random number variables hypothesis is consistent with the data seen through the lens of our model. Since the F from the experiment was generated using random numbers and random choices of variables and \\(\\flex\\) and \\(n\\), the F value is itself random. Now imagine that you repeat the experiment over and over with different random data, different choices of variables, and different \\(\\flex\\). Remarkably, you will find a distribution of F that is centered more or less at 1 and which falls off with larger F. About 95% of the experimental trials, it turns out, will have \\(F &lt; 4\\). Look again at the formula for the margin of error on the effect size, \\[\\mbox{margin of error} = B \\sqrt{4/F}\\] When \\(F &lt; 4\\), which happens 95% of the time, the confidence interval quantity under the radical, \\(\\sqrt{4/F}\\) will be greater than 1. So the margin of interval has a magnitude larger than B itself, meaning that the confidence interval must include zero. Thus, when the “true” effect size is zero, as implemented by the random generation of data, the confidence interval constructed using 4 as the number in \\(\\sqrt{4/F}\\) will include zero 95% of the time. That’s exactly what we want a confidence interval to do. 9.3 4 and \\(n\\) Very precise calculations of the 95% level of F for models fitted to completely random data can be made using advanced mathematics. Of course, such calculations make assumptions about the mechanism generating the random data, which is to say that the calculations are precise only in a specific made-up world. Calling this the “official” standard for the random data world, we can say that officially, the 95% level of F varies somewhat with the sample size \\(n\\) and the model flexibility \\(\\flex\\). This chapter is about confidence intervals on effect sizes from the single explanatory variable in models with \\(\\flex = 1\\), so let’s focus on how official F varies with \\(n\\) when \\(\\flex = 1\\). Figure 9.1: The official 95% values of F to be used in confidence interval calculations are a function of \\(n\\). The blue line marks the value of 4, which is a good match to the official value when \\(n &gt; 10\\). Let’s use the symbol \\(F^\\star\\) to label the “official” 95% values for F. An improved formula for the margin of error of an effect size (when \\(\\flex = 1\\)) is \\[\\mbox{margin of error} = B \\sqrt{F^\\star/F} .\\] For a teacher, it’s worth asking whether to teach the “improved” formula first, or at all. One perspective is that it’s trivial to find \\(F^\\star\\)–just read it off the graph. So why not used the improved formula? There are a few reasons. First, every step in a procedure imposes some cognitive load on students which distracts them from other matters. Second, \\(F^\\star\\) doesn’t explain anything. The explanation of 4 is challenging enough and likely to be understood only by a small fraction of students (unless you spend time doing the simulation). But hardly any math or statistics faculty understand the origins of \\(F^\\star\\) and for students it’s just another mystery. Statistics calculations are always done in practice using software, so \\(F^\\star\\) is automatically included in the computation. More important, there is are issues that make the details of \\(F^\\star\\) relatively unimportant: the choice of measures, the shapes of distributions, and the role of covariates. Insofar as a desire to cover the details of \\(F^\\star\\) causes the instructor to use very small \\(n\\) in examples, the statistics course is being pushed in bad direction. It’s much more important, in today’s world of data, to show how statistics can be applied to realistic problems, which always involve covariates. If you want to teach a unit on “small data,” do that. But it probably won’t be very interesting. 9.4 Confidence versus prediction intervals One of the common mistakes made by students in introductory statistics is to confuse a confidence interval with a prediction interval. For example, consider a confidence interval on the mean commuting time for workers in a city, say 35 to 42 minutes. Experience shows many well educated people will mistake this for a prediction of how long a person’s commute takes, that is, that 95% of people have commuting times in the range 35 to 42 minutes. It’s entirely possible to construct a proper prediction interval. It will typically involve a term in the form of \\(\\pm \\sqrt{4 (v_r - v_m)}\\), which, you should note, does not depend on \\(n\\). For large \\(n\\), the range \\(\\pm \\sqrt{4 (v_r - v_m)}\\) is typically the biggest determinant of a prediction interval. 9.5 For the conventionally trained reader … The conventionally trained reader likely encountered confidence intervals in one of two settings: the CI on the sample mean or the CI on the sample proportion. Relatively simple formulas were presented for the standard error and then the standard error was scaled up by \\(t^\\star\\) or \\(z^\\star\\) to get a confidence interval. We’ll get to CIs on means and proportions in terms analogous to those used in this chapter only Chapter 11. The reason for the delay is that means and proportions are not effect sizes and that there is a mathematical difficulty using the formula for F when \\(\\flex = 0\\). Anticipating Chapter 11 here, a 95% margin of error for a mean or proportion is \\[\\mbox{margin of error} = \\sqrt{4 v_r / n}\\] where \\(v_r\\) is the variance of the variable involved. (For proportions, of course, the variable is an indicator: the mean of an indicator is exactly the proportion of 1s in the indicator.) Recognizing that the \\(\\sqrt{v_r}\\) is the standard deviation \\(s_r\\), we get a formula that is likely more familiar to experienced instructors: \\[\\mbox{margin of error} = 2 s_r / \\sqrt{n}\\] References "],
["so-called-statistical-significance.html", "Chapter 10 So-called “statistical significance” 10.1 Calculating a p-value 10.2 History and criticism 10.3 Appendix: When \\(df \\geq 2\\)", " Chapter 10 So-called “statistical significance” In this book we’ve used effect size as the basic measure of how a response variable is related to an explanatory variable. The confidence interval of an effect size tells what range of values are consistent with our data. When that interval includes zero, it’s fair to say that our data do not rule out the possibility that there is no effect at all, that is, that the response and explanatory variables are unrelated. For historical reasons, its common for researchers to present their results as “statistically significant.” The way a relationship between a respose and explanatory variable(s) can win the certificate of “statistical significance,” is by a process called null hypothesis testing. A null hypothesis test involves calculating a quantity known as the p-value, which is always between 0 and 1. When the p-value is smaller than 0.05 (by convention), the researcher is warranted in using the label “statistically significant.” First, I’ll handle the question of how the calculation is done. Then, I’ll give some history and recent professional recommendations that the result of the calculation has no meaning. Hopefully, despite the ubiquity of p-values in conventional statistics textbooks and in the research literature, you’ll be able to use more meaningful ways to describe the relationship, if any, between response and explanatory variables. 10.1 Calculating a p-value When you quantify the relationship between a response and explanatory variable(s), several inferential quantities are generated. In this book, we focus particularly on F and the degrees of flexibility \\(df\\), from which everything else flows. The p-value calculation takes F, \\(df\\) and sample size \\(n\\) as inputs and produces an output in the form of a probability, that is, a number between 0 and 1. The calculation from first principles is very difficult, so everyone builds on the earlier work of couragious statisticians and mathematicians who have simplifed it into looking up a number in a table, or, more conveniently, asking a computer to look up the number. For example, in the R computing language, the function \\(pf()\\) does the calculation. Specifically, the p-value is 1 - pf(F, df, n - df). In many software systems, such as Excel, all of the F, \\(df\\) and p-value calculations are packaged together in functions that are often called “tests.” There are often many such “tests” provided for different settings like the difference between two means or the slope of a regression line. But the underlying principles are those presented here in a unified way, with \\(v_r\\), \\(v_m\\), \\(df\\), and F. Since what you do with a p-value is to compare it to 0.05, there is a remarkably simple way to go. instead of making the rule about the size of the p-value, we make it about the size of F. The value of F that corresponds to \\(p = 0.05\\) is called the “95% critical value” of F. This is often written F\\(^\\star\\). So long as you have \\(n\\) moderately large, say \\(n \\gtrapprox 10\\), the critical value is 4. That’s it. 4. If \\(n \\gtrapprox 10\\), F=4 is the threshold for declaring a relationship “statistically significant.” For \\(n\\) small, it’s no longer adequate to use 4 as the critical value. Instead, for all the situations encountered in an introductory statistics class, you have to look up the critical value in Figure 1. Sample size \\(n\\) large 10 9 8 7 6 5 4 3 F\\(^\\star\\) 4 5 5.3 5.6 6 7 8 10 19 **Figure 1: Critical values for F depend on the sample size \\(n\\), especially for small \\(n\\). These critical values are for \\(df=1\\). Do remember that the formula for F includes \\(n\\). One way to get a large F is to use data with large \\(n\\). So don’t mis-interpret the table as saying “10 points is enough.” It’s just that F\\(^\\star\\) doesn’t much depend on \\(n\\) when \\(n \\gtrapprox 10\\). Figure 1 is for \\(df = 1\\), which is the situation in most of the settings used in introductory statistics. For larger \\(df\\), the critical values of F are similar except for models where \\(df \\approx n\\). See Figure 3, below. 10.2 History and criticism In the 1880s a way of quantifying the relationship between two numerical variables was invented. It was called the correlation coefficient and it continues to be used to this day. Probably it should not be so widely used today as it is, because we now have effect sizes to work with and because of the challenges to interpreting the correlation coefficient, as you’ll see. The correlation coefficient from the 1880s is closely related to the \\(R^2\\) statistic introduced in Chapter 6. Specifically, the size of the correlation coefficient is \\(r = \\sqrt{R^2} = R\\). Recall that \\(R^2\\) is the ratio of the variance of model values to the variance of the response variable: \\[R^2 \\equiv v_m / v_r.\\] Recall as well that each of \\(v_m\\) and \\(v_r\\) are an average of square differences, and, of course, a square of a real number cannot be less than zero. Consequently, \\(R^2\\) cannot be negative. If \\(R^2\\) is exactly zero, it’s reasonable to conclude that the explanatory variable(s) cannot account for the response variable. Seen another way, if \\(R^2\\) is zero then \\(v_m\\) must also be zero. For \\(v_m\\) to be zero, all of the model values must be exactly the same, so the effect size must also be zero. What happens if – to do a thought experiment – the response variable is completely unrelated to the explanatory variable? You might be anticipating that \\(R^2\\) will be zero. In practice, however, it’s not. This comes about because there are almost always associations happening purely at random that, when quantified, produce \\(R^2 &gt; 0\\). So, in deciding whether the data indicate a relationship between the response and explanatory variable(s), we need to decide what value of \\(R^2\\) is so close to zero as to be a sign that the response and explanatory variable(s) are related. This question was asked, and answered, early in the 1900s. In one specific case, it was asked by a man named Dr Shaw at the January 15, 1907 meeting of the Royal Statistical Society in the UK. The context was a discussion of a paper by Reginald Hooker who had studied the correlation between weather and crops. In Table 1 of his paper, part of which is reproduced in Figure 1, Hooker presented the correlation between amount of wheat harvested and the amount of rain accumulated over the previous seasons. He also looked at the correlation of wheat harvest and temperature – that’s the second numerical column in Figure 2. Now to quote from the recollections published in 1908 by William Seely Gossett, writing anonymously as “Student”: Dr Shaw made an enquiry as to the significance of correlation coefficients derived fronm small numbers of cases. The small number here is 21: Hooker had worked with 21 years of crop and weather data. The plain meaning of “significance of” here is “the meaning carried by.” A modern person might have asked, “Some of those correlations are pretty small. And you don’t have much data. Do such small correlations mean anything?” To continue … His question was answered by Messrs Yule and Hooker and Professor Edgeworth, all of whom considered that Mr Hooker was probably safe in taking .50 as his limit of significance for a sarnple of 21. In plainer language: don’t take as meaningful any correlation coefficient less than 0.50. They did not, however, answer Dr Shaw’s question in any more general way. Now Mr Hooker is not the only statistician who is forced to work with very small samples, and until Dr Shaw’s question has been properly answered the results of such investigations lack the criterion which would enable us to make full use of them. The present paper, which is an account of some sampling experimiients, has two objects: (1) to throw some light by empirical methods on the problem itself, (2) to endeavour to interest mathematicians who have both time and ability to solve it. A general solution was found, in part by Student but also by others such as Ronald Fisher. Key to setting up the solution was to define “significance” in mathematical terms. The setup was logically ingenious and a little hard to follow. It goes like this: Suppose we have two variables that have been generated entirely at random and independently of one another. We can calculate the correlation coefficient between them. The correlation coefficient will also be a random number, presumably near zero. If we perform the experiment many times and collect the set of random correlation coefficients produced, we will have an idea of what is the size of commonly encountered coefficients, and how big a correlation coefficient should be so that we can sensibly regard it as being unlikely to arise from random, independent variables. Doing the random-and-independent-variable simulation for the \\(n = 21\\) situation of Hooker’s paper, indicates that a correlation coefficient at or above 0.50 will result about 1% of the time. That’s a small probability. So, as Messrs Yule, Hooker, and Edgeworth said, it seems “pretty safe” – 99%? – to conclude that \\(r = 0.50\\) with \\(n=21\\) means that there is an association between the two variables. Actually, the simulation only tells us about a hypothetical world – called the Null Hypothesis – in which variables are random and independent. The simulation doesn’t have anything to say about a world in which variables are related to one another. It’s legitimate to say that observing something that’s very unlikely – 1% chance of \\(r \\ge 0.5\\) – suggests that the data didn’t come from that world. But suppose data came from another hypothetical world – called the Alternative Hypothesis – where variables are related to one another. Such a world might easily generate a value \\(r &lt; 0.5\\). So seeing large r entitles us to “reject the null hypothesis,” but seeing small r doesn’t tell us about the alternative hypothesis. Small r just means that we can’t reject the null hypothesis. The formal language is “fail to reject the null hypothesis.” The probability that comes from the null hypothesis simulation has a name: the p-value. In 1925, Ronald Fisher suggested using a probability of 5% instead of 1% in lab work. This guideline was intended to help lab workers avoid making unwarranted claims that an experiment is showing a positive result. If the p-value is \\(p &gt; 0.05\\), you have nothing to say about your experiment, you fail to reject the null hypothesis. Over the years, this got turned around. When \\(p &lt; 0.05\\) (by convention), you’re entitled to “reject the null hypothesis.” In order to publish a scientific report, researchers were obliged to have enough data to reject the null. This is a way of saying that some non-null claim is warranted. But which ones? Certainly the point is to show that there is some substantial relationship between the response and explanatory variable(s), a relationship that means something in the real world. Rejecting the null is not, on its own, a sign that the relationship is substantial and meaningful. Further confusing things was that little word used by Dr Shaw in 1907: significance. An equivalence developed between “reject the null” and “significance.” Claims that had a low p-value came to be described as “statistically significant.” In everyday speech, “significant” means substantial or meaningful or important. This is not the meaning of “statistically significant.” The importance or meaning of an association between a response and explanatory variables can be assessed by looking at the effect size, and checking whether the effect size is large enough to have practical meaning in the world. But even tiny effect sizes, without any practical implications, can generate small p-values. You just have to have enough data. With the phrase “statistically significant” attached to findings, people could publish their work even if there was no practical meaning. It’s worse than this. Even when variables are unrelated, the p-value will be smaller than 0.05 on five percent of occasions. When Fisher was writing in 1925, there weren’t many researchers and each lab experiment required a lot of work. And, in any event, “rejecting the null” was just an internal check on what lab work is worth following up and replicating. But today there are millions of researchers. And each researcher can easily look at dozens of variables. So, even if every researcher was working with unrelated variables, statistical significance will be found millions of times: enough to saturate the literature and effectively hide genuine findings with practical significance. After decades of researchers mis-using p-values, in 2019 the American Statistical Association, a leading professional organization world-wide, issued a statement worth quoting in length: It is time to stop using the term ’statistically significant\" entirely. Nor should variants such as “significantly different,” “p &lt; 0.05,” and “nonsignificant” survive, whether expressed in words, by asterisks in a table, or in some other way. Regardless of whether it was ever useful, a declaration of “statistical significance” has today become meaningless. Made broadly known by Fisher’s use of the phrase (1925), Edgeworth’s (1885) original intention for statistical significance was simply as a tool to indicate when a result warrants further scrutiny. But that idea has been irretrievably lost. Statistical significance was never meant to imply scientific importance, and the confusion of the two was decried soon after its widespread use (Boring 1919). Yet a full century later the confusion persists. And so the tool has become the tyrant. The problem is not simply use of the word “significant,” although the statistical and ordinary language meanings of the word are indeed now hopelessly confused (Ghose 2013); the term should be avoided for that reason alone. The problem is a larger one, however: using bright-line rules for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making (ASA statement, Principle 3). A label of statistical significance adds nothing to what is already conveyed by the value of p; in fact, this dichotomization of p-values makes matters worse. For example, no p-value can reveal the plausibility, presence, truth, or importance of an association or effect. Therefore, a label of statistical significance does not mean or imply that an association or effect is highly probable, real, true, or important. Nor does a label of statistical nonsignificance lead to the association or effect being improbable, absent, false, or unimportant. Yet the dichotomization into “significant” and “not significant” is taken as an imprimatur of authority on these characteristics. In a world without bright lines, on the other hand, it becomes untenable to assert dramatic differences in interpretation from inconsequential differences in estimates. As Gelman and Stern (2006) famously observed, the difference between “significant” and “not significant” is not itself statistically significant. Furthermore, this false split into “worthy” and “unworthy” results leads to the selective reporting and publishing of results based on their statistical significance—the so-called “file drawer problem” (Rosenthal 1979). And the dichotomized reporting problem extends beyond just publication, notes Amrhein, Trafimow, and Greenland (2019): when authors use p-value thresholds to select which findings to discuss in their papers, “their conclusions and what is reported in subsequent news and reviews will be biased…Such selective attention based on study outcomes will therefore not only distort the literature but will slant published descriptions of study results—biasing the summary descriptions reported to practicing professionals and the general public.” For the integrity of scientific publishing and research dissemination, therefore, whether a p-value passes any arbitrary threshold should not be considered at all when deciding which results to present or highlight. 10.3 Appendix: When \\(df \\geq 2\\) For models with multiple explanatory variables or categorical variables with more than two levels, the critical values of F differ substantially from the \\(df = 1\\) case only for very small \\(n\\). Sample size \\(n\\) large 10 9 8 7 6 5 4 3 \\(df = 1\\) 4 5 5.3 5.6 6 7 8 10 19 \\(df = 2\\) 3 4.5 4.7 5.1 5.7 7 9.5 19 200 \\(df = 3\\) 2.7 4.3 4.8 5.4 6.6 9.3 19 216 NA \\(df = 4\\) 2.5 4.5 5.2 6.4 9.1 19 225 NA NA Figure 3: Critical values for F for small \\(n\\) and a few different values of \\(df\\). "],
["simple-means-and-proportions.html", "Chapter 11 Simple means and proportions 11.1 The standard error of the mean and the proportion 11.2 Equivalencies with B, F, and v_m 11.3 t and z", " Chapter 11 Simple means and proportions \\(\\newcommand{\\flex}[]{^\\circ\\!{\\cal{F}}}\\) The presentation of classical inferene in this compact guide does not follow the historical flow of how inferential concepts were developed, largely over the half century from 1880 to 1925. Instead we started with F, which dates from 1925, introducing it in the context of models, an even more recent concept. Models provide a means to address contemporary uses of data. Historically, inference started with very simple-sounding questions involving a single variable. For instance, after observing a mental-health patient’s sleep over several days, a reasonable presentation of how much sleep the patient got is the the mean over those days. Or, in a more contemporary context, imagine being interested in the trend toward self-driving cars. A reasonable summary of the deployment of the technology could be the proportion of cars on the road with self-driving features such as lane-keeping or automatic collision-avoidance braking. Very often, behind the interest in a mean or proportion is a different interest: a change in mean or a change in proportion. For such questions, models and F are the way to go. But in this chapter we’ll journey into means and proportions themselves. 11.1 The standard error of the mean and the proportion We all learned early in our schooling that the mean is calculated by adding up the numbers and dividing by \\(n\\). For instance, the mean of 6, 5, and 10 is 21/3 = 7. We also learned that if we have 15 pieces of fruit, of which 5 are oranges, the proportion of oranges is 5 / 15 = 1/3. But think about the fruit proportion using an indicator variable which will be 1 for oranges and 0 otherwise. The proportion of oranges will be exactly the mean of the indicator variable. In this sense, means and proportions are the same thing. So we’ll focus on the standard error of the mean and not worry about proportions. Every instructor of statistics knows the classical result: the standard error of the mean is \\(s / \\sqrt{n}\\), where \\(s\\) is the standard deviation of the values. In this book we’re not using standard errors–instead we use margins of error, which for 95% confidence are just twice the standard error: \\[\\mbox{margin of error} = 2\\frac{s}{\\sqrt{n}}\\] Similarly, instructors know about a test statistic called t which is the mean divided by the standard error: \\[ t = \\sqrt{n}\\ \\frac{m}{s}\\] where \\(m\\) is the mean. \\(|t| &gt; 2\\) is the threshold for rejecting the null hypothesis (at least for large \\(n\\)). These formulas seem completely different than the ones presented in earlier chapters for models. Traditionally, we teach the standard error of the mean first (with a special but equivalent version for the standard error of the probability). I’ve done the opposite. Now I’m having to introduce special-purpose formula for the simplest of settings: inference on a single mean. I think the underlying problem is that calculations such as a single mean don’t involve one of the basic components of modeling, explanatory variables. Or, if they did, the explanatory variable would be simply a constant; hardly a variable (and in modeling we even call it an “intercept”). 11.2 Equivalencies with B, F, and v_m There is a very strong connection between the classical formulas for t and the standard error and the formulas for F and the margin of error presented much earlier in the book. In particular: \\[t^2 = n \\frac{m^2}{v_r} \\equiv F \\ \\ \\mbox{when}\\ \\flex = 0\\] and \\[\\mbox{margin of error} = 2 \\frac{s}{n} = m \\sqrt{4/F}\\] In other words, there is an equivalence between the F &amp; B formalism presented earlier and the t &amp; standard error formalism classically developed for means. I doubt that these equivalences are helpful in teaching. So I think it is necessary to introduce new formulas to handle confidence intervals and hypothesis testing on the mean. 11.3 t and z Although the standard error of the mean of an indicator variable is the same as the standard error of the corresponding proportion, there is a slight difference in the critical values for very small \\(n\\). I’ve been advocating using the simple critical value \\(F^\\star = 4\\). This, of course, corresponds to \\(z^\\star = 2\\). So I think it’s perfectly reasonable not to distinguish between the 2 that comes from \\(z^\\star\\) and the 2 that comes from \\(\\sqrt{F^\\star}\\) for moderate and large n, even though there is a theoretical argument to be made that the two 2s are different. "],
["comparing-models.html", "Chapter 12 Comparing models 12.1 Complexity and cost 12.2 Why F? 12.3 Analysis of variance 12.4 Analysis of co-variance", " Chapter 12 Comparing models Up to now, we have looked at models individually. It’s time now to examine models in pairs. Such a perspective gives insight into constructing models, for example by including a new explanatory variable in addition to the old ones, or increasing the curvature used in a model function. The basic strategy is simple. Start with an existing model, which we might call \\(\\hbox{mod}_1\\). Then extend or elaborate \\(\\hbox{mod}_1\\) in some way, perhaps by including a new explanatory variable to produce \\(\\hbox{mod}_2\\). We can then examine the increase in the variance of the model values from what it was under \\(\\hbox{mod}_1\\) to what it will be under \\(\\hbox{mod}_2\\). Since we are working with two models, it’s helpful to modify the notation a bit. Before, we had \\(\\hbox{v}_r\\) and \\(\\hbox{v}_m\\), the variance of the response variable and of the model values respectively. We also had R2, which is simply \\(\\hbox{v}_m\\) divided by \\(\\hbox{v}_r\\). We’ll keep \\(\\hbox{v}_r\\) as standing for the variance of the response variable but write \\(\\hbox{v}_1\\) and \\(\\hbox{v}_2\\) as the variance of the model values from \\(\\hbox{mod}_1\\) and \\(\\hbox{mod}_2\\) respectively. Likewise, it’s useful to construct the R-squared ratios for the two models, which we’ll denote \\(\\hbox{R}^2_1\\) and \\(\\hbox{R}^2_2\\), and which are simply \\(\\hbox{v}_1 / \\hbox{v}_r\\) and \\(\\hbox{v}_2 / \\hbox{v}_r\\) respectively. 12.1 Complexity and cost A central question when considering an extending \\(\\hbox{mod}_1\\) into \\(\\hbox{mod}_2\\) is whether the resulting increase in variances, \\(\\Delta \\mbox{v} = \\hbox{v}_2 - \\hbox{v}_1\\) is large enough to justify concluding that extending \\(\\hbox{mod}_1\\) to \\(\\hbox{mod}_2\\) is worth the cost. The “cost?” What cost? Computing the new model \\(\\hbox{mod}_2\\) and its model values is, with a computer, trivial and costs nothing. Rather, the cost of concern is the added complexity of \\(\\hbox{mod}_2\\) compared to \\(\\hbox{mod}_1\\). There is a tradition in science of assuming that, all other things being equal, simpler models are better than more complicated models. Sometimes this tradition is expressed as the “law of parsimony,” as if it were a physical principle (which it is not, until you get very deep into things as in quantum electrodynamics). Sometimes it is given the name “Occams’s Razor” in honor of William of Ockham (c. 1287–1347). Occam’s Latin statement is “Numquam ponenda est pluralitas sine necessitate.” The English translation is scarcely better: “Plurality must never be posited without necessity.” A somewhat earlier formulation might be clearer: “It is superfluous to suppose that what can be accounted for by a few principles has been produced by many.” – Thomas Aquinas (1225–1274) It’s deeply ironic that opinions from the 13th century be quoted as support for scientific principles. At the start of the 20th century, however, some relevant mathematics started to emerge, the mathematics of random walks. This new mathematics provided insight into how complexity of a model might be measured and a criterion for judging whether adding complexity is worthwhile. We’ll put the mathematical theory in a framework that we’ve already developed in earlier chapters. The ingredients are n, the number of rows in the data used to construct the model \\(^\\circ\\!{\\cal{F}}_1\\) and \\(^\\circ\\!{\\cal{F}}_0\\) the degrees of flexibility of \\(\\hbox{mod}_2\\) and \\(\\hbox{mod}_1\\) respectively. \\(\\hbox{R}^2_2\\) and \\(\\hbox{R}^2_1\\) Here are some relevant facts resulting from the mathematical theory of random walks. Fact 1: If \\(\\hbox{mod}_2\\) is an extension of \\(\\hbox{mod}_1\\) (for instance, one created by including an additional explanatory variable) then \\(\\hbox{v}_2 \\geq \\hbox{v}_1\\). Justification: Reach back to Chapter 5 where we considered the process of creating a model function. Recall that the “best” model function is one that comes as close to the response variable as possible, given the selected set of explanatory variables. In extending \\(\\hbox{mod}_1\\), we are giving the process an additional variable to work with. Likely, there will be some way to use that additional variable so that \\(\\hbox{mod}_2\\) gets even closer to the response variable than \\(\\hbox{mod}_1\\). But simply by ignoring the additional variable, \\(\\hbox{mod}_2\\) can at least as close as \\(\\hbox{mod}_2\\). Fact 2: Suppose that all of the explanatory variables are unrelated to the response variable, for instance, they have been created at random. Then a model constructed with n-1 degrees of flexibility will have \\(\\hbox{v}_m = \\hbox{v}_r\\). What’s more, a model with \\(p &lt; n-1\\) degrees of freedom will, on average, have \\(\\hbox{v}_m \\approx \\frac{p}{n-1} \\hbox{v}_r\\). Another way of stating this is that \\[R^2 = \\frac{\\hbox{v}_m}{\\hbox{v}_r} \\approx \\frac{p}{n-1}\\] In support of Fact 2, we’ll do some simulations. In each trial, we’ll generate a small data set with \\(n=11\\). The response variable will come from a random number generator. Similarly we’ll make up p=5 explanatory variables, each of which is also from a random number generator. Then we’ll calculate R2 from each model and look at the distribution. According to the principle, on average \\(R^2 = \\frac{p}{n-1} = \\frac{5}{10}\\). We’ll do the simulation using R software and the mosaic package. I provide the code so that anyone who wants to carry out their own simulation can do so. We’ll do 1000 trials. library(mosaic) Trials &lt;- do(1000) * ( data.frame(y = rnorm(n = 11)) %&gt;% lm(y ~ rand(5), data = .) %&gt;% rsquared() ) mean( ~ result, data = Trials) ## [1] 0.498377 You can repeat the simulation with any n and p that you like to confirm that, on average, \\(R^2 \\approx \\frac{p}{n-1}\\). ## Warning: `data_frame()` is deprecated, use `tibble()`. ## This warning is displayed once per session. 12.2 Why F? We can use Fact 2 to explain why it makes sense for the F-statistic to be defined the way it is. Consider a graph of the average R2 versus \\(^\\circ\\!{\\cal{F}}\\) when all the explanatory variables are made with a random number generator Figure 12.1: (ref:RandomR-cap) In Figure 12.1, the blue point falls at R2=0.65 and \\(^\\circ\\!{\\cal{F}} = 3\\). Referring to the individual random trials with \\(^\\circ\\!{\\cal{F}} = 3\\) (the black dots), you can see that a very small percentage have R2 &gt; 0.65. This alone would cause one to doubt that the explanatory variables used in making the blue dot were purely random. In fact, a p-value for the blue dot could be calculated simply by counting the proportion of black dots that have R-squared larger than the blue dot (for \\(^\\circ\\!{\\cal{F}} = 3\\)). This book is about classical inference, so the use of simulation, a computer-era technique, is out of place. Classical inference resorts to a different observation. In Figure 12.1, there are two blue segments. One connects the origin to the blue dot, the other connects the blue dot to the upper-right corner of the plot. We’ll call the left-most segment the “model segment,” since it reflects Clearly the slope of segment one is larger than the slope of segment two. This will happen whenever the blue dot is above the vertical range of the random trials. But for the random trials, on average, the two slopes would be about the same. So, under the Null Hypothesis that the explanatory variables are unrelated to the response variable, the ratio of slopes will be about 1. Fisher suggested using the ratio of slopes in the R2 versus \\(^\\circ\\!{\\cal{F}} = 3\\) graph as a test statistic. Given a blue dot with its R2 and \\(^\\circ\\!{\\cal{F}} = 3\\), the slope of segment one is \\(\\mbox{R}^2_1 / ^\\circ\\!{\\cal{F}}\\). Similarly, the slope of segment two is \\((1 - \\mbox{R}^2_2) / (n - (^\\circ\\!{\\cal{F}} +1))\\). The ratio of slope one to slope two is F. Figure 12.2: Figure 12.2. Translating the \\(R^2\\) and \\(^\\circ\\!{\\cal{F}}\\) values from Figure 12.1 into the corresponding F value shows a much simpler version. On average, the F values from the random simulation are about \\(F=1\\) regardless of \\(^\\circ\\!{\\cal{F}}\\). Similarly, almost all the random trials produce \\(F &lt; 4\\). Fisher deduced these facts using algebra and calculus with the mathematics of random walks, a remarkable achievement. Today, it takes only a moderate amount of computer-programming skill to confirm them. 12.3 Analysis of variance The word “analysis” refers to the process of breaking something down into its constituent components. (The antonym is “synthesis,” the process of bringinging components together to form a whole.) The phrase “analysis of variance” concisely describes the strategy for examining a model that consists of components. For example, we’ve described \\(\\hbox{mod}_2\\) as being an extension of \\(\\hbox{mod}_1\\) – mod_2 consists of \\(\\hbox{mod}_1\\) plus some additional component. In undertaking analysis of variance, the quantity that is being broken down is the variance r of the response variable. When working with a single model, the variance is broken down into two components: m, the variance accounted for by the model what’s left over, the residual variance, which is simply r - m. In the previous section, I’ve chosen to report not the variance itself, but the proportion of the variance of the response variable: \\(R^2 = \\hbox{v}_m / \\hbox{v}_r\\), the proportion accounted for by the model \\(1 - R^2 = (\\hbox{v}_r - \\hbox{v}_m) / \\hbox{v}_r\\), the residual proportion of the variance. The idea of analysis of variance can be extended to the situation of a model \\(\\hbox{mod}_2\\) which has been built as an extension to a model \\(\\hbox{mod}_1\\). The situation is sketched in Figure 12.3. First, calculate \\(\\hbox{R}^2_1\\), the proportion of the variance accounted for by \\(\\hbox{mod}_1\\). Second, calculate \\(\\hbox{R}^2_2\\), the proportion of the variance captured by \\(\\hbox{mod}_2\\). In Figure 12.3, \\(\\hbox{R}^2_1\\) is the left-most blue dot, while \\(\\hbox{R}^2_2\\) is the other blue dot. The two blue dots divide the domain of the graph into three components: the model-one segment, the model-two segment, and the residual segment. To address the question of whether \\(\\hbox{mod}_2\\) meaningfully extends \\(\\hbox{mod}_1\\), we compare the slope of the model-two segment to that of the residual segment. This ratio of slopes, which we can call \\(\\Delta \\hbox{F}\\), is the test statistic. If \\(Delta\\hbox{F} \\gtrapprox 4\\), it’s fair to conclude that the extension to \\(\\hbox{mod}_1\\) is discernably different from an extension that would have been concocted from random explanatory variables unrelated to the response variable. Figure 12.3: Figure 12.3: looking at how the extensions to \\(\\hbox{mod}_1\\) contained in \\(\\hbox{mod}_2\\) increase \\(\\mbox{R}^2_2\\) compared to \\(\\mbox{R}^2_1\\) As a formula, the ratio of the slopes of the model-two segment to the model-one segment is: \\[\\Delta \\mbox{F} = \\frac{n - (^\\circ\\!{\\cal F}_{2} + 1)}{^\\circ\\!{\\cal F}_{2} - ^\\circ\\!\\!{\\cal F}_{1}} \\cdot \\frac{\\hbox{R}^2_{2} - \\hbox{R}^2_{1}}{1 - \\hbox{R}^2_{2}}\\] 12.4 Analysis of co-variance It sometimes happens that \\(\\hbox{mod}_1\\) contains all the explanatory variables of direct interest and the point of building \\(\\hbox{mod}_2\\) is to include those covariates which ought to be taken into consideration but are not of direct interest. In this situation, the ratio of interest is the slope of the model-one segment to the slope of the residual segment. This is called “analysis of co-variance.” I like to describe the purpose of including the covariates in \\(\\hbox{mod}2\\) as “eating variance.” That is, the covariates can reduce the slope of the residual segment, making it easier for the model-one segment to look steep by comparison. "],
["remember-inference-isnt-everything.html", "Chapter 13 Remember, inference isn’t everything 13.1 Substantiality 13.2 Causal reasoning 13.3 Confounding 13.4 The stars of statistical inference", " Chapter 13 Remember, inference isn’t everything A famous calculus textbook exercise provides a helpful perspective on how mathematical formulations can get something exactly right while at the same time getting it hopelessly wrong. The exercise is about tin cans and asks what is the best height and circumference of a cylinder that encloses a specified volume while using a minimum of material in the package. The tin-can problem has an exact solution; there is a specific combination of height and circumference that does the job. But that solution is also wrong because it ignores most of the real-world aspects of the problem. For instance, tin cans have a crimped edge on top, which consumes material while not contributing to volume. As well, in cutting out the circular caps for the can, material is wasted: the unused interstices between circles. And there is the thickness of the material, which needs to be strong enough to resist puncture and crushing, perhaps calling for horizontal corrugations in the cylinder. Manufacturability is an issue: there’s a reason why the paper-and-foil “sanipacks” are a rectangular prism rather than a cylinder. Then there is the question of why the volume is being set at the specified value, as well as myriad other considerations: the feel of the can in the hand and the pourability of the shape (which can argue for a can that’s wider than it is deep), the suitability for being opened with conventional can openers, the desire to make a marketing statement with a distinctive shape, the efficiency with which the can uses the available space in shipping containers, stackability and stockability on supermarket shelves, and so on. Certainly the cost of the can material should come into play – if material is cheap and the contents are expensive, perhaps advertising and marketing considerations trump a theoretical optimality of shape. Now let’s talk about statistics. The roots of classical inference are in problems of astronomy and geodesy: how to combine varying measurements to get the best estimate of the position of a planet or the length of a line of longitude, and how to figure out how precise that estimate is. Combining lots of individual measurements means that the “normal” distribution is relevant. But it’s a stretch to think that combining three measurements of a dodgy biological quantity should be interpreted in the same way. And, when the subject of study is variation between individuals, it’s odd to focus student attention on central estimates–mean, median–rather than on extremes. However nice the mathematics of classical inference, there are real-world conditions that need to be taken into account: the appropriate use of covariates, the many choices made by researchers in shaping the algorithm used to calculate the reported quantity, the relative cost and importance of an error of one type versus an error of the other type. Classical inference–certainly that presented in introductory statistics–is shaped by one concern and one concern only: how to deal with the variation introduced by random sampling or assignment. When data are very limited, it may sometimes be that sampling variation is the largest contributor to error. But when data are plentiful, the many other considerations become more pressing. In today’s world, data are often cheap, like tin plate. Optimizing a statistical design to minimize the need for data is much like insisting on an optimally cylindrical can despite all the other objectives involved in marketing, storing, and shipping food. In my view, our statistical curriculum has been much too dismissive of the human factors in interpreting and using statistical results. To inform decision makers, many of whom have negligible quantitative skills, the analysis needs to be plausible and compelling. There needs to be a believable way to demonstrate that an approach is correct: appealing to algebra and textbook expertise does not necessarily accomplish what’s needed. Real-world costs and benefits need to be quantifiable, something quite different than declaring a significance threshold of 0.05 (and, even then, substantially ignoring the issue of statistical power). And if causality is the motivating factor, we need to provide tools for students to take causality seriously. It’s a shame that a narrow consideration of sampling variation came to capture the word “inference,” as if sampling variation were the only object of statistical reasoning. Of course it’s not, and as a reminder in this chapter I’ll look briefly at three matters that ought not be ignored when trying to draw inferences about the world from data: substantiality, unobserved confounders, and the lessons from the last quarter century’s work on causality. 13.1 Substantiality Consider this claim on a patient-oriented medical website6 about statins, a class of drugs used to improve cholesterol levels in people: Statins quickly reduce LDL, the “bad,” cholesterol by 50% or more. Statins boost HDL, the “good” cholesterol, by up to 15%. A statistical educator might point out that these statements lack a supporting inferential claim. The everyday English qualifiers “or more” and “up to” are an informal way of indicating that there is some uncertainty, but statisticians might prefer a confidence interval, say that LDL is reduced by 50% ± 10%. What does the ±10% bring to our interpretation? Perhaps it suggests that most statin-takers see a reduction in the range 40-60%. That’s wrong. Knowing the confidence interval puts no bound on the distribution of individual responses. The interval 40-60% is perfectly compatible with some people seeing an increase in LDL. Wouldn’t it be better to report something like “70% of statin takers see a reduction of 25% or more in LDL levels?” On the other hand, what’s special about 25%? Or 50% for that matter? Presenting the LDL reduction in an informative way needs to be based on how important or substantial is that reduction. For instance, here is a report from the Journal of the American College of Cardiology: Among rosuvastatin-allocated participants, 3,640 individuals (46.3%) experienced an LDL-C reduction ≥50%; 3,365 individuals (42.8%) experienced an LDL-C reduction &gt;0 but &lt;50%; and 851 individuals (10.8%) experienced no reduction or an increase in LDL-C compared with baseline. The report goes on to link the reduction in LDL to an outcome that people might reasonably care about: avoiding “cardiovascular events” (CVE). The results: placebo group: 11.2 events per 1,000 person-years statin-taking group no reduction in LDL: 9.2 events per 1,000 person-years reduction less than 50%: 6.7 events per 1,000 person-years reduction greater than 50%: 4.8 events per 1,000 person years. Comparing each of the statin-taking subgroups to the placebo produces a “hazard ratio,” which is no LDL reduction: 0.91 (95% CI 0.54–1.53) less than 50% reduction: 0.61 (95% CI, 0.44–0.83) greater than 50% reduction: 0.43 (95% CI, 0.30–0.60) The confidence intervals are important tools. Here, they tell us that CVE risk is reduced (on average) for people with LDL reduction. They also indicate little reason to think the less than 50% subgroup is different from the greater than 50% subgroup. But let’s return to the events per 1,000 person years. Those are odd-sounding units, so it might be tempting to favor the hazard ratios. But in terms of the impact of statin-taking on human health, the event rate is more telling. A reduction of 50% in LDL is associated with a change in event incidence of about 5 per 1,000 person-years or, equivalently, 1 per 200 person-years. Of course, nobody takes a statin for 200 years, but the number is still informative. Assuming people take statins for 10 years, the results suggest that a group of 20 people taking statins successfully would avoid one cardiovascular event; in other words, the “number needed to treat” is twenty. It’s fair to consider the “number needed to treat” as the substance of the effect on CVE of taking statins (at least in those who respond with a lowering in LDL). Of course there are other effects of statins that need to be balanced against the observed reduction in CVE when making a clinical decision. Only with a handle on the substantiality of the effect of statins, not just the statistical significance, are you in a position to judge translations of the science into everyday recommendations. Going back to the patient-facing web site at the start of this section, what does the substance suggest about the value of this interpretation: “`Statins are very simple: You take them once a day, and their effects are quite profound,’ says Patrick McBride, MD, MPH, director of the cholesterol clinic at the University of Wisconsin School of Medicine and Public Health.” Maybe not so simple or profound after all. It can be difficult for students or instructors to determine what kind of effect is substantial in any given context. Still, students should be exposed to formats for expressing substance (like “number needed to treat”) and to look for substance-related claims (or the lack thereof) when interpreting statistical studies. 13.2 Causal reasoning Traditionally, introductory statistics courses emphasize the idea that “correlation is not causation.” This is only true in the sense that knowing that there is a correlation between X and Y does not tell you which way the direct causal link between X and Y, if any, goes. I prefer to say that “correlation is causation.” (a) (b) (c) (d) X \\(\\rightarrow\\) Y X \\(\\leftarrow\\) Y X \\(\\leftarrow\\) C \\(\\rightarrow\\) Y X \\(\\rightarrow\\) C \\(\\leftarrow\\) Y There are other possibilities that are variations on (c) and (d) with a causal connection between X and Y, for instance networks (e), (f), and (g): (e) (f) (g) Data can help narrow down the possibilities. For instance, network (c) will produce data where Y is independent of X when adjusted for C but where X and Y are correlated when C is ignored. Conversely, network (d) produces X independent of Y when C is ignored, but correlated when adjusting for C. If the goal is to study the possible causal relationship between X and Y, then in network (e) C should be ignored, in network (f) C should be adjusted for, and in network (g) C should be ignored. It’s often the case that people have preferred hypotheses about what causes what. It’s important to carry out the analysis that corresponds correctly to your hypothesis. Even when there is disagreement over hypotheses, the discussion can be moved along by comparing the correlations found in the data (e.g. X and Y, conditioned on C) and checking whether they are consistent with the various hypotheses. The role of randomized assignment in experiment is to create a network with known properties about which reasonable people will agree.7 For instance, if C is the random assignment to X of drug or placebo, we can be sure that X doesn’t cause C and similarly that Y doesn’t cause C. In the language of econometrics, a C that reflects randomized assignment is called an “instrumental variable.” In the absence of experiment, sometimes it’s possible to find an instrumental variable created naturally, a setting which gives strong credibility to causal claims deduced from observational data. Understanding the legitimate possibilities for causal reasoning from observational data can help students distinguish between causal claims that warrant belief and those that are undeserving. 13.3 Confounding The phrase “lurking variable” is used to warn students of the possibility of a hidden, perhaps unknown variable creating a spurious correlation, that is a correlation that is not dispositive of a causal relationship. Unfortunately, the possibility of lurking variables can lead to a kind of statistical nihilism, where any claim can be rejected based on the mere assertion of a possible lurking variable. Actually, it is possible to get a handle on how much influence a plausible lurking variable can have on a statistical claim of causal connection. Jerome Cornfield led the way here in 1959. The setting was the well-established association between smoking and lung cancer. Famously, Ronald Fisher asserted that the association could not be treated as a causal connection. He speculated that there could be a genetic lurking variable that is a common cause for both smoking behavior and lung cancer. In the notation of networks, the hypothesized genetic variable plays the role of C in network (f) above, with X being smoking and Y lung cancer. In order properly to study the possible effect of X on Y, it’s necessary to adjust for C. But genetic science in 1959 offered little guidance about what the lurking gene might be and therefore no way to measure it and adjust for it. Cornfield realized that there might, nonetheless, be something to say. He wrote: If an agent, A, with no causal effect upon the risk of a disease, nevertheless, because of a positive correlation with some other causal agent, B, shows an apparent risk, r, for those exposed to A, relative to those not so exposed, then the prevalence of B, among those exposed to A, relative to the prevalence among those not so exposed, must be greater than r. – Cornfield J et al. Smoking and lung cancer: recent evidence and a discussion of some questions. JNCI 1959;22:173–203. Reprint available here. In the context of smoking and cancer, Cornfield’s A is smoking and B is the hypothesized genetic common cause of smoking and cancer. The observed risk ratio for lung cancer between smokers and non-smokers was about 9. As such, both the risk ratio for the link between cancer and the lurking gene and the risk ratio between smoking and the lurking gene would need to be greater than 9. Such strong links between genetics and complex phenotypes8 would be exceptional. Cornfield’s realization tipped the genetics hypothesis into the trash can of history. To mitigate the statistical nihilism of lurking variables, we can pose a mathematical question. Suppose that some plausible lurking variable C might has a correlation of R2 with X and also with Y. (For simplicity, we’ll assume the same R applies to C \\(\\rightarrow\\) X and to C \\(\\rightarrow\\) Y.) A correlation corresponds to a geometrical alignment. If C is aligned with X, and C is aligned with Y, we can examine the consequences for the possible alignment of X and Y. If the R2 of the lurking variable with the variables of interest is very small, then possible confounding can only be weak. If we see a strong relationship between X and Y, only a small part of that can be attributed to confounding. On the other hand, if the R2 of the lurking variable with X and with Y is large, and the observed relationship between X and Y is weak, it seems reasonable to dismiss the X-Y relationship as the product of confounding. I’ve put together the geometry of such mutual alignments in a format that I’ll call the “confounding interval.” The confounding interval depends both on the strength of the X-Y relationship and on the lurking C-X and C-Y relationships. In marked contrast to a confidence interval, the confounding interval does not depend on the sample size. Figure 13.1: Figure 13.1. A confounding interval. Three bands are shown, each a function of the observed correlation between X and Y. The narrowest band corresponds to a weak lurking R2 of 0.04, the largest to a comparatively strong lurking R2 of 0.35. The upper and lower bounds of each band are to be multiplied by the observed X-Y effect size, giving a range of effect sizes that are plausible outcomes from the suspected confounding. To illustrate, suppose that observed X-Y data indicates points to a relationship with \\(\\mbox{R}^2_{XY} = 0.1\\) and an effect on Y with respect to X of \\(B\\). (For large sample sizes, the confidence interval on \\(B\\) will be vary narrow. We’ll assume that the confidence interval is well away from zero. We suspect that, to some extent, the observed effect size might be influenced by a lurking variable. Since the lurking variable is unobserved and unknown, there’s no way to know what is its actual alignment with X and Y. But we can establish a policy of caution based on the amount of intellectual work we have done to rule out unknown confounders. Perhaps like this: Did a perfect experiment? Use \\(\\mbox{R}^2{CX} = 0\\). Did a real experiment? Use \\(\\mbox{R}^2{CX} = 0.04\\). Know a lot about the system you’re observing and confident that the significant confounders have been adjusted for? Use \\(\\mbox{R}^2{CX} = 0.08\\). Not sure what all the confounders might be, but controlled for the ones you know about? Use \\(\\mbox{R}^2{CX} = 0.16\\). Got some data and you want to use it to figure out the relationship between X and Y? Use \\(\\mbox{R}^2{CX} = 0.35\\). Suppose we’re in intellectual situation (5); we haven’t given any thought to possible confounding variables. We have observed an effect size–say, a regression slope and its confidence interval–of, say, 10 ± 3 y-units/x-units. At \\(\\mbox{R}^2_{XY} = 0.1\\) the appropriate upper and lower bounds are about -0.2 to 1.2. The confounding interval on the effect size will therefore be \\(-0.2 \\times 10\\) to \\(1.2 \\times 10\\), with an additional ±3 at each end. In other words, the confounding interval will be -5 to 15, much wider than the confidence interval of 7 to 13. Without giving thought to possible confounding variables, we’re not in a position even to say that the effect size is different from zero. In intellectual situation (4), in contrast, the upper and lower bounds of the band are 0.3 to 0.95. Correspondingly, the confounding interval will be \\(0.3 \\times 10\\) to \\(0.95 \\times 10\\), with the additional ±3 from the confidence interval. Altogether, that’s a confounding interval of 0 to 12.5. In situation (3) the confounding interval will be 6 to 10, with the additional ±3 from the confidence interval, giving 3 to 13. Note that if the observed \\(\\mbox{R}^2_{XY}\\) is large, the confounding interval would be smaller than in the previous examples. Notice also that unknown confounding pulls the interval toward a weaker relationship than that naively observed. 13.4 The stars of statistical inference A typographical convention in reporting p-values uses stars. One star stands for \\(p &lt; 0.05\\), two stars for \\(p &lt; 0.01\\), and three stars for \\(p , 0.001\\). As a quick way to guide the eye, this is not a bad convention. But it falsely suggests that the p-value is the measure of statistical quality. In the Michelin restaurant ratings, for instance, a one-star restaurant is remarkable and a three-star restaurant excels by a global standard. To move toward a more comprehensive evaluation of statistical claims, I propose a revision to the star system. Let’s start by insisting that there be some meaningful statement of the smallest effect size worth mentioning (SEWM). This should be a non-zero value and justification should be given about the practical import of such an effect. This will, of course, depend on the context. The effect of a drug that reduces blood pressure on average by 1 mmHg in a large experimental group will be undetectable in individuals: not worth mentioning. So one star for an effect size whose confidence interval has both bounds exceeding the SEWM. Let’s award a second star when a statistical analysis has appropriately considered covariates. A third star when causal reasoning has been applied appropriately and when a confounding interval reported. A fourth star for a result based on experiment or a convincingly established instrumental variable. Finally, a fifth star when the result has been independently confirmed. With this scale, the kinds of non-experimental results often found in typical introductory statistics book won’t earn even a single star, simply because they lack the minimal connection to the real world created by establishing the smallest effect worth mentioning. Stepped-wedge design "],
["getting-started-in-your-classroom.html", "Chapter 14 Getting started in your classroom", " Chapter 14 Getting started in your classroom To start incorporating the Compact approach to your class, you might: Start the course in the usual way. Move through the topics you like up through the confidence interval on a mean and proportion. DON’T do hypothesis testing yet. Additional topic: Try to introduce the variance along with the standard deviation. There’s a nice explanation in Chapter 3 that you might find helpful. Additional topic: Demonstrate that calculating a proportion is the same as calculating the mean of an indicator variable. Use models rather than “two sample” or “differences.” Present actual data in a response variable vs explanatory variable format. Use the Point Plot Little App to make graphics with both categorical and quantitative response and explanatory variables. Project such plots on the board or print them on paper. Have students practice drawing models. Don’t worry about exact calculations yet. If you want exact, you can use the Proportions and Point Plot Little Apps. "]
]
